{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyMVfEK+s1vWPUY+vhqmwOYy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n","|-|:-:|\n","|<h2>Part 5:</h2>|<h1>Observation (non-causal) mech interp<h1>|\n","|<h2>Section:</h2>|<h1>Investigating token embeddings<h1>|\n","|<h2>Lecture:</h2>|<h1><b>CodeChallenge: SVD projections of related embeddings<b></h1>|\n","\n","<br>\n","\n","<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n","<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">udemy.com/course/dullms_x/?couponCode=202508</a></h5>\n","<i>Using the code without the course may lead to confusion or errors.</i>"],"metadata":{"id":"Ct-OEMBkJ-wV"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"WTp8j3TJAqvB"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from matplotlib.gridspec import GridSpec\n","\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"]},{"cell_type":"code","source":["# load BERT tokenizer and model\n","from transformers import BertTokenizer, BertModel\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","model = BertModel.from_pretrained('bert-base-uncased')\n","embeddings = model.embeddings.word_embeddings.weight.detach().numpy()"],"metadata":{"id":"IlLTVTpTBS75"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"FF6s6MTMKKec"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 1: Tokenize and create embeddings submatrices\n"],"metadata":{"id":"nKAaswpTKKbu"}},{"cell_type":"code","source":["digitTokens = np.zeros(10,dtype=int)\n","\n","# find the token index for this numer\n","for i in range(10):\n","\n","  # confirm they're all single-token words\n","  toks = tokenizer.encode(str(i), add_special_tokens=False)\n","  print(f'{len(toks)} token for \"{i}\"')\n","\n","  digitTokens[i] = toks[0]"],"metadata":{"id":"ukSKw-qmKPIA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# list of 10 EU countries\n","EUstates = ['estonia','france','germany','italy','latvia','lithuania','netherlands','poland','romania','slovenia' ]\n","\n","\n","# find the token index for this numer\n","EUtokens = np.zeros(len(EUstates),dtype=int)\n","for i in range(len(EUstates)):\n","\n","  # confirm they're all single-token words\n","  toks = tokenizer.encode(EUstates[i], add_special_tokens=False)\n","  print(f'{len(toks)} token for \"{EUstates[i]}\"')\n","\n","  EUtokens[i] = toks[0]"],"metadata":{"id":"DvbPZRVJU0Ch"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get the category-mean embeddings vector for later centering\n","\n","# for countries (expand to a row vector for later broadcasting)\n","EU_embedMean = embeddings[EUtokens,:].mean(axis=0)[None,:]\n","\n","# and for digits\n","digs_embedMean = embeddings[digitTokens,:].mean(axis=0)[None,:]\n","\n","\n","# any obvious relationship?\n","plt.plot(EU_embedMean,digs_embedMean,'ko',markerfacecolor=[.9,.9,.7,.6])\n","plt.gca().set(xlabel='EU average',ylabel='Digits average',\n","              title=f'Correlation = {np.corrcoef(EU_embedMean,digs_embedMean)[0,1]:.3f}')\n","plt.show()"],"metadata":{"id":"wKp6eh4ZZgHJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create embeddings submatrices\n","\n","# numbers\n","subembDigs = embeddings[digitTokens,:] - digs_embedMean\n","\n","# countries\n","subembEU = embeddings[EUtokens,:] - EU_embedMean"],"metadata":{"id":"jay5W0ulLT66"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"uBLJaftygWl_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 2: Extract and visualize the singular value spectrum"],"metadata":{"id":"iGYjCo9TgWjD"}},{"cell_type":"code","source":["# SVDs (note: python returns Vt [technically Vh], so the rows of V are the singular vectors)\n","U_dig,s_dig,V_dig = np.linalg.svd(subembDigs)\n","\n","# and for EU\n","U_EU,s_EU,V_EU = np.linalg.svd(subembEU)\n","\n","# print sizes\n","print(f'Embeddings is size {subembDigs.shape}')\n","print(f'U  is size {U_EU.shape}')\n","print(f's  is size {s_EU.shape}')\n","print(f'Vh is size {V_EU.shape}')"],"metadata":{"id":"FacwE7BciSDe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# visualize\n","_,axs = plt.subplots(1,2,figsize=(12,5))\n","\n","# plot their spectra\n","axs[0].plot(s_dig,'ks-',markerfacecolor=[.7,.7,.9],label='Digits',markersize=10)\n","axs[0].plot(s_EU,'ko-',markerfacecolor=[.9,.7,.7],label='EU',markersize=10)\n","axs[0].set(xlabel='Component (sorted index)',ylabel='Singular value',title='Spectrum of embeddings submatrices',xlim=[-.5,9.5])\n","axs[0].legend()\n","\n","# plot the top singular vectors\n","axs[1].plot(V_EU[0],V_dig[0],'ko',markerfacecolor=[.7,.9,.7,.7])\n","axs[1].set(xlabel='EU basis vector',ylabel='Digits basis vector',\n","           title=f'Singular vectors (r = {np.corrcoef(V_EU[0],V_dig[0])[0,1]:.2f})')\n","\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"Bwkkw0quLT4J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"vaBHqdkrLTyn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 3: Project embeddings onto basis vectors"],"metadata":{"id":"fMR6nmYBKgDk"}},{"cell_type":"code","source":["# projection of EU-centered embeddings onto the top eigenvector (first row of Vt)\n","projEU = (embeddings-EU_embedMean) @ V_EU[0,:]\n","projDg = (embeddings-digs_embedMean) @ V_dig[0,:]\n","\n","plt.figure(figsize=(10,4))\n","\n","# histograms\n","yD,xD = np.histogram(projDg,bins=90,density=True)\n","yE,xE = np.histogram(projEU,bins=90,density=True)\n","\n","plt.plot(xD[:-1],yD,linewidth=2,label='Digits')\n","plt.plot(xE[:-1],yE,linewidth=2,label='EU countries')\n","plt.legend()\n","\n","plt.gca().set(xlabel='Embedding dimension',ylabel='Density',title='Distributions of projections')\n","plt.show()"],"metadata":{"id":"WjiBEKMUPBsK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print top 30 projection tokens\n","sortidx = np.argsort(projEU)\n","\n","# print the top positive projections\n","print('--- POSITIVE projections ---')\n","for i in range(30):\n","\n","  # get this token\n","  token = tokenizer.decode(sortidx[-i])\n","\n","  # print if it's not in the 'seed' list\n","  if not token in EUstates:\n","    print(f'  {projEU[sortidx[-i]]:6.3f} for \"{token}\"')\n","\n","\n","# repeat for top negative projections\n","print('\\n\\n\\n--- NEGATIVE projections ---')\n","for i in range(30):\n","\n","  # get this token\n","  token = tokenizer.decode(sortidx[i])\n","\n","  # print if it's not in the 'seed' list\n","  if not token in EUstates:\n","    print(f'  {projEU[sortidx[i]]:6.3f} for \"{token}\"')"],"metadata":{"id":"WNK2Iz0uPBo3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# repeat for numbers\n","sortidx = np.argsort(projDg)\n","\n","# print the top positive projections\n","print('--- POSITIVE projections ---')\n","for i in range(30):\n","\n","  # get this token\n","  token = tokenizer.decode(sortidx[-i])\n","\n","  # print if it's not in the 'seed' list\n","  if not token in '0123456789':\n","    print(f'  {projDg[sortidx[-i]]:6.3f} for \"{token}\"')\n","\n","\n","# repeat for top negative projections\n","print('\\n\\n\\n--- NEGATIVE projections ---')\n","for i in range(30):\n","\n","  # get this token\n","  token = tokenizer.decode(sortidx[i])\n","\n","  # print if it's not in the 'seed' list\n","  if not token in '0123456789':\n","    print(f'  {projDg[sortidx[i]]:6.3f} for \"{token}\"')"],"metadata":{"id":"T3OjD809PBmA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"LcpEp4h6PBjG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 4: Cosine similarities of the embeddings"],"metadata":{"id":"XzZzGnT1Py0c"}},{"cell_type":"code","source":["# normalize each vector to its norm (unit length)\n","E_digs = subembDigs  / np.linalg.norm(subembDigs, axis=1,keepdims=True)\n","E_EU   = subembEU / np.linalg.norm(subembEU,axis=1,keepdims=True)\n","\n","# cosine similarity matrices\n","csM_EU = E_EU  @ E_EU.T\n","csM_dg = E_digs @ E_digs.T\n","\n","fig,axs = plt.subplots(1,2,figsize=(10,4))\n","\n","h = axs[0].imshow(csM_EU,vmin=-.5,vmax=.5)\n","axs[0].set(xticks=range(10),xticklabels=EUstates,yticks=range(10),yticklabels=EUstates)\n","axs[0].tick_params(axis='x',labelrotation=90)\n","fig.colorbar(h,ax=axs[0],pad=.02)\n","\n","axs[1].imshow(csM_dg,vmin=-.5,vmax=.5)\n","axs[1].set(xticks=range(10),yticks=range(10))\n","fig.colorbar(h,ax=axs[1],pad=.02)\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"zdZH66NJNWpz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"OvIEzaaINWiG"},"execution_count":null,"outputs":[]}]}