{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyPt2dGdPZm/gDyRchVzLbeS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n","|-|:-:|\n","|<h2>Part 5:</h2>|<h1>Observation (non-causal) mech interp<h1>|\n","|<h2>Section:</h2>|<h1>Investigating neurons and dimensions<h1>|\n","|<h2>Lecture:</h2>|<h1><b>Extracting activations using \"hooks\"<b></h1>|\n","\n","<br>\n","\n","<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n","<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">udemy.com/course/dullms_x/?couponCode=202508</a></h5>\n","<i>Using the code without the course may lead to confusion or errors.</i>"],"metadata":{"id":"mlcJM5uEHZ6h"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"RuKeB769HOkN"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import torch\n","from transformers import GPT2Model, GPT2Tokenizer\n","\n","model = GPT2Model.from_pretrained('gpt2')\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","\n","# vector plots\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"]},{"cell_type":"code","source":["model.eval()"],"metadata":{"id":"pwOFGK_BHZ1W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.config"],"metadata":{"id":"GFhK_SBDmUN5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"knXVkxUYp3Ey"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Manually access the activations of a layer"],"metadata":{"id":"mMJZk8iIqZDX"}},{"cell_type":"code","source":["# variable for the embedding dimensionality\n","embed_dim = model.config.n_embd\n","\n","# random numbers for inputs (1 batch, 20 tokens)\n","inputActs = torch.randn(1,20,embed_dim)\n","print(f'Inputs into layer is {inputActs.shape}')\n","\n","# run the data (output of previous layer) through this weights matrix\n","# 3rd attention block, QKV matrix\n","outputActs = model.h[3].attn.c_attn(inputActs[0])\n","print(f'Outputs from QKV is {outputActs.shape}')\n","\n","# isolate just the Q neuron outputs\n","Q = outputActs[:,:embed_dim]\n","print(f'Q activations is {Q.shape}')"],"metadata":{"id":"xItdgaKnHaaZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"jqTjLQ3NrqHj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Implanting a hook in the model"],"metadata":{"id":"YI_EkZGRHaXr"}},{"cell_type":"code","source":["## references:\n","# https://pytorch.org/docs/stable/generated/torch.nn.modules.module.register_module_forward_hook.html\n","# https://stackoverflow.com/questions/78279823/how-exactly-the-forward-and-backward-hooks-work-in-pytorch"],"metadata":{"id":"aR6NyLacsZbR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define a hook function to store query vectors\n","activations = {}\n","\n","def implant_hook(layer_number): # need an \"outer\" function here to specify the layer_number\n","  def hook(module, input, output):\n","\n","    # module: the layer the hook is attached to\n","    # input : a tuple of the inputs passed into that layer during the forward pass\n","    # output: output of that layer\n","\n","    # pass the inputs into the attention block (QKV matrices concatenated)\n","    qkvActs = module.c_attn(input[0])  # [batch, seq, 3*embed_dim]\n","\n","    # isolate the Q activations before they're further processed during attention\n","    embed_dim = qkvActs.shape[-1] // 3\n","    qActs = qkvActs[:,:,:embed_dim].detach()\n","\n","    # store in the dictionary\n","    activations[f'attn_{layer_number}_q'] = qActs\n","\n","    ### note: Here we're not taking the output of the entire layer; we're selectively grabbing\n","    #         the Q activations before they're combined during self-attention.\n","    #         That's why we re-calculate and extract. cf the following line (not used here!),\n","    #         where the stored activations correspond to the layer output (post-attention-computations).\n","    activations[f'attn_output_{layer_number}'] = output\n","\n","  return hook\n","\n","\n","# pick the layers to hook\n","layers2hook = [5,7]\n","handles = [None]*len(layers2hook)\n","\n","\n","# surgery ;)\n","handles[0] = model.h[layers2hook[0]].attn.register_forward_hook(implant_hook(layers2hook[0]))\n","handles[1] = model.h[layers2hook[1]].attn.register_forward_hook(implant_hook(layers2hook[1]))"],"metadata":{"id":"3kRaud4VHY6T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# see the hook in the model\n","model.h[layers2hook[0]].attn._forward_hooks"],"metadata":{"id":"e4l8mfitUHGl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"FH-Q2xkK49Sz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# \"Hook\" the activations"],"metadata":{"id":"fIfKI4MN8yvE"}},{"cell_type":"code","source":["text = 'This is an example sentence.'\n","tokens = tokenizer.encode(text,return_tensors='pt')\n","\n","# forward pass to trigger the hook\n","outputs = model(tokens)"],"metadata":{"id":"ksnGrkwiUFMo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# activations are not in the outputs...\n","dir(outputs)"],"metadata":{"id":"HUWeJWIloE08"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ... they're stored in the dictionary\n","activations"],"metadata":{"id":"9KCzxL1U2rt8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# check stored activations\n","qq = activations['attn_5_q']\n","print(f'Size of query matrix: {qq.shape}')"],"metadata":{"id":"9BF45hrLUB1s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"hi_Dest47mWt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Hooked data are replaced at each forward pass"],"metadata":{"id":"-Y8T2XGq84da"}},{"cell_type":"code","source":["# run again to see replacement\n","\n","print('First run:\\n',activations['attn_5_q'])\n","\n","tokens = tokenizer.encode('This is a different sentence',return_tensors='pt')\n","outputs = model(tokens)\n","\n","print('\\nSecond run:\\n',activations['attn_5_q']) # they are the same!"],"metadata":{"id":"EPMjERgO3UA4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# see the next hook implantation for how to save all previous activations!"],"metadata":{"id":"60bDG_dy3T7D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"zNzOAcWgP7AS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Some visualizations"],"metadata":{"id":"hIvAdKGa89GA"}},{"cell_type":"code","source":["# visualization\n","plt.plot(qq[0,3,:],qq[0,2,:],'ko',markerfacecolor=[.9,.8,.7],alpha=.6)\n","plt.gca().set(xlabel=f'Activation to \"{tokenizer.decode(tokens[0,3])}\"',\n","              ylabel=f'Activation to \"{tokenizer.decode(tokens[0,2])}\"',\n","              title='Activations of Q neurons in layer 5')\n","plt.show()"],"metadata":{"id":"fv2_kkvrm5mV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# correlation matrix\n","plt.imshow(np.corrcoef(np.squeeze(qq)),vmin=-.8,vmax=.8)\n","plt.colorbar()\n","plt.show()"],"metadata":{"id":"b8YGteFam5je"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3nU1Xv2mm5bC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Removing hooks"],"metadata":{"id":"cJfQJTxY9BGP"}},{"cell_type":"code","source":["# hooks can be removed\n","print('Preserved hook before removal:\\n',activations['attn_5_q'][0,-1,:6])\n","print('Removed hook before removal:\\n',activations['attn_7_q'][0,-1,:6])\n","\n","# remove one hook\n","handles[1].remove()\n","\n","# new tokens\n","tokens = tokenizer.encode('I wish coffee tasted like toothpaste',return_tensors='pt')\n","\n","outputs = model(tokens)\n","\n","print('\\nPreserved hook after removal:\\n',activations['attn_5_q'][0,-1,:6])\n","print('Removed hook after removal:\\n',activations['attn_7_q'][0,-1,:6])"],"metadata":{"id":"Hsxsq7xWT8KZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# remove the other hook\n","handles[0].remove()"],"metadata":{"id":"ZLbVbMQaQLDV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"B1iK8SO87cMP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Appending instead of replacing activations"],"metadata":{"id":"zVwElrAsP2Yt"}},{"cell_type":"code","source":["# hook the MLP's output\n","activations = []\n","\n","# note: don't need an \"outer function\" call here b/c we specify the hook layer below\n","def mlp_hook(module, inp, out):\n","  activations.append(out)\n","\n","# hook the MLP in layer 4\n","model.h[4].mlp.c_proj.register_forward_hook(mlp_hook)"],"metadata":{"id":"246W0YvTP2V8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# run some text through the model\n","model( tokenizer.encode('I like chocolate.',return_tensors='pt') );"],"metadata":{"id":"xZlmeftsQeV4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# note: just a list, not a dictionary!\n","activations"],"metadata":{"id":"6bPYmHtSQeSy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f'\"activations\" is a {type(activations)} that contains {len(activations)} elements \\n')\n","for i in range(len(activations)):\n","  print(f'Element {i} has shape {activations[i].shape}')"],"metadata":{"id":"fESbxeIBQePg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# run the model THREE more times\n","model( tokenizer.encode('I like chocolate.',return_tensors='pt') )\n","model( tokenizer.encode('You know the shape my breath will take before I let it out.',return_tensors='pt') )\n","model( tokenizer.encode('Four score and seven years ago.',return_tensors='pt') );"],"metadata":{"id":"No81t-UoRUj5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f'\"activations\" is a {type(activations)} that contains {len(activations)} elements \\n')\n","for i in range(len(activations)):\n","  print(f'Element {i} has shape {activations[i].shape}')"],"metadata":{"id":"8Ry3xF09RUeu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"61JtRfLjRiDg"},"execution_count":null,"outputs":[]}]}