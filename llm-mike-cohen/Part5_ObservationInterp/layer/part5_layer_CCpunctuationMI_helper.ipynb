{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyMl9TAWtMARZfqG2hHXQajf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n","|-|:-:|\n","|<h2>Part 5:</h2>|<h1>Observation (non-causal) mech interp<h1>|\n","|<h2>Section:</h2>|<h1>Investigating layers<h1>|\n","|<h2>Lecture:</h2>|<h1><b>CodeChallenge HELPER: Clusters in internal vs. terminal punctuation<b></h1>|\n","\n","<br>\n","\n","<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n","<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">udemy.com/course/dullms_x/?couponCode=202508</a></h5>\n","<i>Using the code without the course may lead to confusion or errors.</i>"],"metadata":{"id":"1Jy0D6mE78uS"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from matplotlib.gridspec import GridSpec\n","import matplotlib as mpl\n","\n","import requests\n","\n","import torch\n","\n","# vector plots\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"],"metadata":{"id":"aoocnKDi-2RN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"L_5xIvYA--eH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 1: Model and punctuation indices"],"metadata":{"id":"gfLe3fZX9kqm"}},{"cell_type":"code","source":["# load pretrained GPT-2 model and tokenizer\n","from transformers import AutoModelForCausalLM,GPT2Tokenizer\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","gpt2 = AutoModelForCausalLM.from_pretrained('gpt2-medium')\n","gpt2 = gpt2.to(device)\n","gpt2.eval()\n","nEmb = gpt2.config.n_embd\n","\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2-medium')"],"metadata":{"id":"bHKfbxSx-B5Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text = requests.get('https://www.gutenberg.org/cache/epub/219/pg219.txt').text # Heart of Darkness\n","tokens =\n","num_tokens =\n","\n","print(f'There are {} tokens, {} of which are unique.')"],"metadata":{"id":"QqQENLC_8gJ3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# tokens to match exactly\n","internal_punctuations =\n","terminal_punctuations =\n","\n","\n","# initialize vector\n","isPunctuation = np.zeros\n","\n","# loop over all tokens (ignore starting tokens before the book starts)\n","for ti in range(\n","\n","  # current token\n","  currtok = # also remove preceeding spaces\n","\n","\n","  # test for punctuation\n","  if currtok in # if it's an internal punctuation\n","      isPunctuation[ti] =\n","\n","  # check if it's terminal -- and not a decimal-point number!\n","  elif currtok in terminal_punctuations:\n","    if # not a decimal point\n","      isPunctuation[ti] = 2\n","\n","\n","# report\n","print(f'There are:\\n  {sum(isPunctuation==1):3} internal punctuation marks, and\\n  {sum(isPunctuation==2):3} terminal punctuation marks.')"],"metadata":{"id":"P7EgksOB2Rqi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"vb86hzbwgTQQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# find the indices\n","internalIdx =\n","terminalIdx =\n","\n","# examine some punctuations\n","context_win = 9\n","for t in terminalIdx[:5]:\n","  print(f'Example {t}:\\n{}\\n')"],"metadata":{"id":"YIzCv9xAxqrg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"KqtdhfcQ9jOF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 2: Create batches and get activations"],"metadata":{"id":"tbA-5s4SD9mv"}},{"cell_type":"code","source":["# some data parameters\n","batchsize   =\n","context_pre =\n","context_pst ="],"metadata":{"id":"S1sy2jikiETI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create batches\n","batch_internal = torch.zeros((batchsize, # initialize to integers\n","batch_terminal = torch.zeros((batchsize,\n","\n","# loop over sequences to create batches\n","for b in range(batchsize):\n","\n","  # internal punctuations\n","  tokenLoc = internalIdx[b]\n","  batch_internal[b,:] =\n","\n","  # terminal punctuations\n","\n","\n","\n","batch_terminal.shape"],"metadata":{"id":"-FMLAjEmI1hm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# process the internal tokens\n","with torch.no_grad():\n","  output_internal = gpt2(batch_internal.to(device),output_hidden_states=True)\n","\n","# repeat for terminal tokens\n"],"metadata":{"id":"KtC8DXBhxqkl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(output_internal.hidden_states[3].shape)\n","len(output_internal.hidden_states)"],"metadata":{"id":"dOFc8S1KAQ_2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# for convenience, bring the activations to the CPU in a shorter-named variable\n","hsIntern = []\n","hsTermin = []\n","\n","for i in range(len(output_internal.hidden_states)):\n","  hsIntern.append( output_internal.hidden_states[i] # convenient to have in numpy format\n","  hsTermin."],"metadata":{"id":"48ZJREDcP5Wj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hsIntern[4].shape"],"metadata":{"id":"mB-PEZ91BWWa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# visualize\n","\n","# average target tokens over all sequences\n","ave_intern = hsIntern[3]\n","ave_termin = hsTermin[3]\n","\n","_,axs = plt.subplots(1,2,figsize=(10,4))\n","\n","axs[0].plot(ave_intern,'o',label='Internal')\n","axs[0].plot(ave_termin,'s',label='Terminal')\n","\n","axs[1].plot(\n","axs[1].set(xlabel='Internal',ylabel='Terminal',title='Scatter plot of activations')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"TsHRDxPdF9t2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"PFf_mmw38Oqm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 3: MI and cov in one layer"],"metadata":{"id":"IGTU_e5Z8OhQ"}},{"cell_type":"code","source":["# a function for mutual information\n","def mutInfo_and_cov(x,y,outlierThresh=0):\n","\n","  # remove outliers based on a z-score threshold\n","  if outlierThresh>0:\n","    zx = (x-mean) / std\n","    zy =\n","    outlier = # if either variable exceeds the threshold\n","    x = # remove outliers from the data\n","    y = # make sure the same exact indices are removed from both variables\n","\n","\n","  # histogram and convert to proportion (estimate of probability)\n","  Z  = np.histogram2d(x,y,bins=15)[0]\n","  pZ = # normalize by sum\n","  px = pZ.sum(axis=1)\n","  py =\n","\n","  # calculate entropy\n","  eps = 1e-12\n","  Hx = -np.sum( px * np.log2(px+eps) )\n","  Hy = -np.sum(\n","  HZ =\n","\n","  # mutual information\n","  MI =\n","\n","  # and covariance\n","  C = sum( ()*() ) / ()\n","\n","  return MI,C"],"metadata":{"id":"uJ4OBO06F5ss"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# sanity-check target index ;)\n","tokenizer.decode(batch_terminal[3,context_pre])"],"metadata":{"id":"lCRNLNgwTD4T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# this cell takes ~40 sec\n","whichLayer = 1 # 20\n","\n","mi_in = np.zeros((batchsize,batchsize))\n","mi_tr = np.zeros((batchsize,batchsize))\n","cov_in = np.zeros\n","cov_tr = np.zeros\n","\n","\n","\n","# double-loop over the token pairs\n","for bi in range(batchsize):\n","  for bj in range(bi+1,batchsize):\n","\n","    ## internal punctuation\n","    # extract the data\n","    x = hsIntern[whichLayer\n","    y = hsIntern\n","\n","    # pairwise mutual information and covariance\n","    mi_in[bi,bj],cov_in[bi,bj] =\n","\n","\n","    ## repeat for terminal punctuation\n",""],"metadata":{"id":"XthpUT_tHcuV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# a variable to extract and vectorize the unique matrix elements\n","uniqueIndices = np.triu_indices(batchsize\n","uniqueIndices"],"metadata":{"id":"lzfBw0DgYXgd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"kHKvsELdDAM6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# visualize all pairwise MI from one layer\n","\n","fig = plt.figure(figsize=(8,6))\n","gs = GridSpec(2,2,figure=fig)\n","ax0 = fig.add_subplot(gs[0,0])\n","ax1 = fig.add_subplot(gs[0,1])\n","ax2 = fig.add_subplot(gs[1,:])\n","\n","\n","# show the matrices\n","h = ax0.imshow(,vmin=,vmax=,origin='lower',aspect='auto')\n","plt.colorbar(h,ax=ax0,fraction=.046,pad=.02)\n","ax0.set(xticks=[],yticks=[],xlabel='Sequence index',ylabel='Sequence index',title='Pairwise MI for INTERNAL')\n","\n","h = ax1.imshow(\n","plt.colorbar(h,ax=ax1,fraction=.046,pad=.02)\n","ax1.set(xticks=[],yticks=[],xlabel='Sequence index',ylabel='Sequence index',title='Pairwise MI for TERMINAL')\n","\n","\n","# get histograms from nonzero elements\n","yIntern,xIntern = np.histogram(mi_in # just the unique elements\n","yTermin,xTermin = np.histogram(mi_tr\n","\n","# and show those\n","ax2.plot(,label='Internal',linewidth=2)\n","ax2.plot(,label='Terminal',linewidth=2)\n","ax2.set(xlim=[min(xIntern[0],xTermin[0]),max(xIntern[-1],xTermin[-1])],\n","        xlabel='Mutual information',ylabel='Count',title='Distribution of MI values')\n","ax2.legend()\n","\n","\n","plt.tight_layout()\n","plt.suptitle(f'Mutual information in layer {whichLayer}',y=1.05,fontweight='bold',fontsize=16)\n","plt.show()"],"metadata":{"id":"iTU3bFqHIeK0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# visualize all pairwise covariance from one layer\n","\n","fig = plt.figure(figsize=(8,6))\n","gs = GridSpec(2,2,figure=fig)\n","ax0 = fig.add_subplot(gs[0,0])\n","ax1 = fig.add_subplot(gs[0,1])\n","ax2 = fig.add_subplot(gs[1,:])\n","\n","\n","# show the matrices\n","h = ax0.imshow(\n","plt.colorbar(h,ax=ax0,fraction=.046,pad=.02)\n","ax0.set(xticks=[],yticks=[],xlabel='Sequence index',ylabel='Sequence index',title='Pairwise MI for INTERNAL')\n","\n","h = ax1.imshow(\n","plt.colorbar(h,ax=ax1,fraction=.046,pad=.02)\n","ax1.set(xticks=[],yticks=[],xlabel='Sequence index',ylabel='Sequence index',title='Pairwise MI for TERMINAL')\n","\n","\n","# get histograms from nonzero elements\n","\n","\n","# and show those\n","\n","ax2.set(xlim=[min(xIntern[0],xTermin[0]),max(xIntern[-1],xTermin[-1])],\n","        xlabel='Covariance',ylabel='Log count',title='Distribution of covariance values')\n","ax2.legend()\n","\n","\n","plt.tight_layout()\n","plt.suptitle(f'Covariance in layer {whichLayer}',y=1.05,fontweight='bold',fontsize=16)\n","plt.show()"],"metadata":{"id":"0tQ0K8svSfQ4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"clBUHUJdqCtm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## covariance by mutual information\n","\n","_,axs = plt.subplots(1,3,figsize=(12,4))\n","\n","# skip to facilitate plotting\n","pnts2skip = 17\n","\n","# plot the internal punctuations\n","axs[0].plot(,,'.',markerfacecolor=[.7,.7,.9,.3])\n","axs[0].set(xlabel='Covariance',ylabel='Mutual information',\n","           title=f'Internal punctuation (r = {np.corrcoef(cov_in[uniqueIndices],mi_in[uniqueIndices])[0,1]:.3f})')\n","\n","# plot the terminal punctuations\n","\n","axs[1].set(xlabel='Covariance',ylabel='Mutual information',\n","           title=f'Terminal punctuation (r = {np.corrcoef(cov_tr[uniqueIndices],mi_tr[uniqueIndices])[0,1]:.3f})')\n","\n","\n","\n","axs[2].set(xlabel='Covariance',ylabel='Mutual information',title='Both')\n","axs[2].legend()\n","\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"rcM5f_DwX-bf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"pcgcUT_C8OVO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 4: MI and cov over all layers"],"metadata":{"id":"4XAhyDBhnyaJ"}},{"cell_type":"code","source":["# initializations\n","mi_in_all = np.zeros((len(hsIntern),batchsize,batchsize))\n","mi_tr_all = np.zeros((len(hsIntern),batchsize,batchsize))\n","cv_in_all = np.zeros((len(hsIntern),batchsize,batchsize))\n","cv_tr_all = np.zeros((len(hsIntern),batchsize,batchsize))\n","\n","\n","# loop over layers\n","for layeri in range(len(hsIntern)):\n","\n","  # double-loop over the token pairs\n","  for bi in range(batchsize):\n","    for bj in range(bi+1,batchsize):\n","\n","      ## internal punctuation\n","      x = hsIntern\n","      y = hsIntern\n","      mi_in_all[layeri,bi,bj],cv_in_all[layeri,bi,bj] =\n","\n","      ## repeat for terminal punctuation\n","\n","  print(f'Finished layer {layeri+1:2}/{len(hsIntern)}')"],"metadata":{"id":"r-tc1ZUQnyUJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# scatter plots\n","_,axs = plt.subplots(5,5,figsize=(12,11))\n","axs = axs.flatten()\n","\n","\n","# skip to facilitate plotting\n","pnts2skip = 7\n","\n","for layeri\n","\n","  # plot the dots\n","  axs[layeri].plot(cv_in_all[],mi_in_all[],'r.',alpha=.2,label='Intermediate')\n","  axs[layeri].plot(cv_tr_all[],mi_tr_all[],'k.',alpha=.2,label='Terminal')\n","\n","  # adjust the axis\n","  axs[layeri].set(xticks=[],yticks=[],title=f'Layer {layeri}')\n","\n","axs[20].set(xlabel='Covariance',ylabel='Mutual information')\n","axs[20].legend(fontsize=8)\n","\n","plt.tight_layout()\n","# plt.savefig('ex4.png')\n","plt.show()"],"metadata":{"id":"W_x59ohsyIS8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"jnwIJ8GAo1Dv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 5: Distributions and means"],"metadata":{"id":"i4k5k1zqwFDN"}},{"cell_type":"code","source":["fig,axs = plt.subplots(2,2,figsize=(10,6))\n","\n","# normalization function for mapping layer index onto color\n","norm = mpl.colors.Normalize(vmin=0,vmax=len(hsIntern))\n","\n","# loop over layers\n","for layeri in rang\n","\n","  ### covariance: plot the distribution\n","  yy,xx = np.histogram(cv_in_all[\n","  axs[0,0].plot(xx[:-1],yy,color=mpl.cm.plasma(norm(layeri)))\n","\n","  # and the mean of the distribution\n","  axs[0,1].plot(layeri,.mean(),'ks',\n","              markersize=10,markerfacecolor=mpl.cm.plasma(norm(layeri)))\n","\n","\n","\n","  ### mutual information\n","\n","  axs[1,0].plot(xx[:-1],yy,color=mpl.cm.plasma(norm(layeri)))\n","\n","  # and the mean\n","\n","\n","\n","# add colorbars\n","sm = mpl.cm.ScalarMappable(cmap=mpl.cm.plasma,norm=norm)\n","plt.colorbar(sm,ax=axs[0,0],pad=.01)\n","plt.colorbar(sm,ax=axs[1,0],pad=.01)\n","\n","# labels and titles\n","axs[0,0].set(xlabel='Covariance value',ylabel='Density',title='Covariance distribution')\n","axs[0,1].set(xlabel='Hidden layer',ylabel='Covariance',title='Average covariances')\n","axs[1,0].set(xlabel='Mutual information value',ylabel='Density',title='MI distribution')\n","axs[1,1].set(xlabel='Hidden layer',ylabel='Mutual information',title='Average MI values')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"t8OYqQx9o1Ao"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"sE-SD4Ea45Z_"},"execution_count":null,"outputs":[]}]}