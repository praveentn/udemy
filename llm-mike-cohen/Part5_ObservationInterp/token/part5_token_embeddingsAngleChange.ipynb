{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyORCcWBJZJg0mi0IM4LKwyb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n","|-|:-:|\n","|<h2>Part 5:</h2>|<h1>Observation (non-causal) mech interp<h1>|\n","|<h2>Section:</h2>|<h1>Investigating token embeddings<h1>|\n","|<h2>Lecture:</h2>|<h1><b>Calculating rotations of embeddings vectors<b></h1>|\n","\n","<br>\n","\n","<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n","<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">udemy.com/course/dullms_x/?couponCode=202508</a></h5>\n","<i>Using the code without the course may lead to confusion or errors.</i>"],"metadata":{"id":"RDgvq3mX1Vsh"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"5BvQj17hzqwM"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# for the stats\n","import scipy.stats as stats\n","\n","import torch\n","from transformers import AutoModelForCausalLM, GPT2Tokenizer\n","\n","# vector graphs\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"]},{"cell_type":"code","source":["# load GPT2 model and tokenizer\n","model = AutoModelForCausalLM.from_pretrained('gpt2-xl')\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2-xl')\n","\n","model.eval()"],"metadata":{"id":"vEwYHoqWz0nB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"MTvKXQXK1aJf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Sentences with \"her\" as target"],"metadata":{"id":"2tRtnyyI9fp_"}},{"cell_type":"code","source":["# generated by Claude.ai\n","sentences = [\n","    \"I saw her at the market.\",\n","    \"She gave her the book.\",\n","    \"They asked her for advice.\",\n","    \"We invited her to dinner.\",\n","    \"The dog followed her home.\",\n","    \"They asked her to join.\",\n","    \"He saw her at the park yesterday.\",\n","    \"Did you give her your address?\",\n","    \"I haven't seen her in ages.\",\n","    \"I told her the truth.\",\n","    \"They congratulated her on his success.\",\n","    \"She recognized her immediately.\",\n","    \"The teacher praised her for his work.\",\n","    \"I met her last summer.\",\n","    \"The child hugged her tightly.\",\n","    \"They warned her about the danger.\",\n","    \"She drove her to the airport.\",\n","    \"We waited for her for hours.\",\n","    \"The cat scratched her accidentally.\",\n","    \"They surprised her with a gift.\",\n","    \"She called her on the phone.\",\n","    \"The jury found her not guilty.\",\n","    \"I remembered her from school.\",\n","    \"They elected her as president.\",\n","    \"She forgave her for his mistake.\",\n","    \"The police questioned her yesterday.\",\n","    \"I helped her with his homework.\",\n","    \"They spotted her in the crowd.\",\n","    \"She visited her in the hospital.\",\n","    \"The manager promoted her last week.\",\n","    \"I trusted her completely.\",\n","    \"They respected her for his honesty.\",\n","    \"She taught her how to swim.\",\n","    \"The bird attacked her suddenly.\",\n","    \"I greeted her warmly.\",\n","    \"They supported her through difficult times.\",\n","    \"She ignored her at the party.\",\n","    \"The judge sentenced her to community service.\",\n","    \"I photographed her during the event.\",\n","    \"They believed her despite the evidence.\",\n","    \"She surprised her on his birthday.\",\n","    \"The guard stopped her at the entrance.\",\n","    \"I missed her terribly.\",\n","    \"They watched her leave the building.\",\n","    \"She accompanied her to the concert.\",\n","    \"The crowd cheered her enthusiastically.\",\n","    \"I described her to the police.\",\n","    \"They thanked her for his help.\",\n","    \"She admired her for his courage.\",\n","    \"The committee nominated her for the award.\",\n","    \"I married her last spring.\",\n","    \"They informed her about the changes.\",\n","    \"She introduced her to the parents.\",\n","    \"The author based the character on her.\"\n","]\n","\n","target_token = tokenizer.encode(' her')[0]\n","print(f'There are {len(sentences)} sentences.')"],"metadata":{"id":"q8Fuw-ug1aBU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# need to specify a padding token\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","# tokenize\n","tokens = tokenizer(sentences,padding=True,return_tensors='pt')\n","\n","# push through the model (~1 min for gpt2-xl in cpu)\n","with torch.no_grad():\n","  outputs = model(**tokens,output_hidden_states=True)"],"metadata":{"id":"iYx21qIa34uN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_hiddens = len(outputs.hidden_states)\n","seq_len = outputs.hidden_states[3].shape[1]\n","\n","n_hiddens,outputs.hidden_states[3].shape"],"metadata":{"id":"JUpXNloJ6F1T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"0Dx-ZC5devyX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get angle of token vector from previous to current layer\n","\n","angles = np.zeros((n_hiddens-1,len(sentences),3))\n","\n","\n","for senti in range(len(sentences)):\n","\n","  # find the index of the target token (convert to list, then .index to find)\n","  targidx = tokens['input_ids'][senti].tolist().index(target_token)\n","\n","  for layeri in range(1,n_hiddens):\n","\n","    # TARGET: calculate the angle between this and the previous layer activations\n","    v = outputs.hidden_states[layeri-1][senti,targidx,:].detach().squeeze()\n","    u = outputs.hidden_states[layeri  ][senti,targidx,:].detach().squeeze()\n","    angles[layeri-1,senti,0] = torch.acos( torch.dot(v,u) / (torch.linalg.norm(v) * torch.linalg.norm(u) ) )\n","\n","    # NON-TARGET: calculate the angle between this and the previous layer activations\n","    v = outputs.hidden_states[layeri-1][senti,targidx-1,:].detach().squeeze()\n","    u = outputs.hidden_states[layeri  ][senti,targidx-1,:].detach().squeeze()\n","    angles[layeri-1,senti,1] = torch.acos( torch.dot(v,u) / (torch.linalg.norm(v) * torch.linalg.norm(u) ) )\n","\n","    # SHUFFLED: angle between random pairs of vectors and layers\n","    v = outputs.hidden_states[torch.randint(1,n_hiddens,(1,))][senti,torch.randint(seq_len,(1,)),:].detach().squeeze()\n","    u = outputs.hidden_states[torch.randint(1,n_hiddens,(1,))][senti,torch.randint(seq_len,(1,)),:].detach().squeeze()\n","    angles[layeri-1,senti,2] = torch.acos( torch.dot(v,u) / (torch.linalg.norm(v) * torch.linalg.norm(u) ) )\n","\n","angles.shape"],"metadata":{"id":"xVnYAo_79JRO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# optional conversion from radians to degrees\n","angles = angles * 180/np.pi"],"metadata":{"id":"ueDr9125DJOY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(11,4))\n","\n","xticks = np.arange(1,n_hiddens)\n","\n","# plot all the individual sentences\n","plt.plot(xticks,angles[:,:,0],color=[.9,.7,.7],alpha=.5)\n","plt.plot(xticks,angles[:,:,1],color=[.7,.7,.9],alpha=.5)\n","\n","# and the average over sentences\n","plt.plot(xticks,angles[:,:,0].mean(axis=1),'r',linewidth=3,label='Target')\n","plt.plot(xticks,angles[:,:,1].mean(axis=1),'b',linewidth=3,label='Non-target')\n","\n","# completely shuffled angles\n","plt.plot(xticks,angles[:,:,2],color=[.7,.9,.7],alpha=.5)\n","plt.plot(xticks,np.nanmean(angles[:,:,2],axis=1),'g',linewidth=3,label='Shuffled')\n","\n","plt.legend()\n","plt.gca().set(xlabel='Transformer layer',ylabel='Angle (rad.)',xlim=[0,n_hiddens],#ylim=[.03,.3],\n","              title=r'$\\Delta v^{\\circ}$ relative to previous layer')\n","\n","plt.show()"],"metadata":{"id":"hj91zRXTs71Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"7fZegcAwKBxx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Statistical evaluation"],"metadata":{"id":"xY7QsXtnKBur"}},{"cell_type":"code","source":["# t-tests\n","tres = stats.ttest_rel(angles[:,:,0].T,angles[:,:,1].T)\n","\n","# extract data and get boolean significance (corrected for multiple comparisons)\n","t = tres.statistic\n","issig = tres.pvalue<.05/n_hiddens\n","\n","# plot!\n","plt.figure(figsize=(10,4))\n","\n","# plot the significant values\n","plt.plot(xticks[issig & (t>0)],t[issig & (t>0)],'ko',\n","         markersize=9,markerfacecolor=[.7,.9,.7],label='Target > nontarget')\n","plt.plot(xticks[issig & (t<0)],t[issig & (t<0)],'ks',\n","         markersize=9,markerfacecolor=[.7,.7,.9],label='Nontarget > target')\n","\n","# and the non-significant values\n","plt.plot(xticks[~issig],tres.statistic[~issig],'rx',label='Non-sig.')\n","plt.axhline(0,linestyle='--',color='gray')\n","\n","# touch-ups\n","plt.legend()\n","plt.gca().set(xlabel='Layer',ylabel='T-value',title='Statistical significance of rotation differences')\n","\n","plt.show()"],"metadata":{"id":"9Oy0nfHoB5qe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"aelKIKNxGYp1"},"execution_count":null,"outputs":[]}]}