{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyOAW5rhJLTWnnBUVGFhf8t2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n","|-|:-:|\n","|<h2>Part 6:</h2>|<h1>Intervention (causal) mech interp<h1>|\n","|<h2>Section:</h2>|<h1>Editing hidden states<h1>|\n","|<h2>Lecture:</h2>|<h1><b>Downstream impact of early layer scaling<b></h1>|\n","\n","<br>\n","\n","<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n","<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">udemy.com/course/dullms_x/?couponCode=202508</a></h5>\n","<i>Using the code without the course may lead to confusion or errors.</i>"],"metadata":{"id":"_gPy1MwYgrhi"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"6NPsr5B0nv52"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","\n","from transformers import GPT2LMHeadModel, GPT2Tokenizer\n","import torch\n","\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"]},{"cell_type":"code","source":[],"metadata":{"id":"UfsFsErkUM5e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Import a model, implant hooks"],"metadata":{"id":"iatcALxyUM26"}},{"cell_type":"code","source":["model = GPT2LMHeadModel.from_pretrained('gpt2')\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","model.eval()"],"metadata":{"id":"oK0xvp_0HVbf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# scaling factor\n","scaling_factor = 1\n","\n","# scale output by some amount\n","def hook(module, input, output):\n","  hidden, *rest = output # unpack the tuple\n","  hs = hidden.clone()\n","  hs.mul_(scaling_factor)\n","  return (hs,*rest) # pack the output back into a tuple\n","\n","# hard-coded to use layer 2\n","model.transformer.h[2].register_forward_hook(hook)"],"metadata":{"id":"tu2mnCz4OV93"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"rRPU7E0SUMH4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Create tokens and get activations"],"metadata":{"id":"xbXvRpFLUQLk"}},{"cell_type":"code","source":["tokens = tokenizer.encode('Duct tape will very useful after the apocalypse.',return_tensors='pt')"],"metadata":{"id":"QRBxnFQCMtDQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get the hidden states\n","scaling_factor = 1\n","with torch.no_grad():\n","  out = model(tokens,output_hidden_states=True)\n","\n","hs_pure = out.hidden_states\n","\n","print(f'There are {len(hs_pure)} hidden_states.')\n","print(f'Each hidden state is of size {list(hs_pure[3].shape)}')"],"metadata":{"id":"WlaHvncoOV6-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"6kWtOTiIUTLb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Scale a layer and visualize the impact"],"metadata":{"id":"i8QcAtmCUTFE"}},{"cell_type":"code","source":["# now scale one layer\n","scaling_factor = .5\n","with torch.no_grad():\n","  out = model(tokens,output_hidden_states=True)\n","\n","hs_scale = out.hidden_states"],"metadata":{"id":"pJty-UoBLjMf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["layer_norm = np.zeros(len(hs_scale))\n","\n","# calculate the norm of the change between each layer\n","for layeri in range(len(hs_scale)):\n","\n","  # extract embeddings vectors for all-but-first token\n","  pure = hs_pure[layeri][0,1:,:].detach().numpy()\n","  scal = hs_scale[layeri][0,1:,:].detach().numpy()\n","\n","  # calculate and store matrix norm difference\n","  layer_norm[layeri] = np.linalg.norm(pure-scal)"],"metadata":{"id":"OSrHTqPzMj1x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(8,3))\n","\n","plt.plot(layer_norm,'ks-',markerfacecolor=[.7,.9,.7],markersize=10,linewidth=.5)\n","\n","xlabels = ['emb'] + [f'T{i}' for i in range(model.config.n_layer)]\n","plt.gca().set(xlabel='Hidden state',xticks=range(len(hs_pure)),xticklabels=xlabels,\n","              ylabel='Matrix difference norm',title='Difference between scaled and unscaled hidden states')\n","plt.show()"],"metadata":{"id":"EECCD5tGMjy0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"2ZCdzl9iMZxG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Explore a range of scaling factors"],"metadata":{"id":"jvHMtoVKMZuV"}},{"cell_type":"code","source":["# the scaling\n","scale_factors = np.linspace(.5,1.5,21)\n","\n","# initialize the results matrix\n","layer_norms = np.zeros((len(hs_scale),len(scale_factors)))\n","\n","\n","# loop over scaling factors\n","for scalei in range(len(scale_factors)):\n","\n","  # set the new scaling factor\n","  scaling_factor = scale_factors[scalei]\n","\n","  # run the model and get hidden states\n","  with torch.no_grad(): out=model(tokens,output_hidden_states=True)\n","  hs_scale = out.hidden_states\n","\n","  # calculate the norm of the change between each layer\n","  for layeri in range(len(hs_scale)):\n","\n","    # extract embeddings vectors for all-but-first token\n","    pure = hs_pure[layeri][0,1:,:].detach().numpy()\n","    scal = hs_scale[layeri][0,1:,:].detach().numpy()\n","\n","    # calculate and store matrix norm difference\n","    layer_norms[layeri,scalei] = np.linalg.norm(pure-scal)"],"metadata":{"id":"Sv2d4OZ0eltj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig,axs = plt.subplots(1,2,figsize=(10,3))\n","\n","# plot each layer (in a loop for color specification)\n","for scalei in range(len(scale_factors)):\n","  axs[0].plot(layer_norms[:,scalei],'.-',color=mpl.cm.plasma(scalei/len(scale_factors)))\n","\n","# create a colorbar for the lines\n","norm = mpl.colors.Normalize(vmin=scale_factors[0],vmax=scale_factors[-1])\n","sm = mpl.cm.ScalarMappable(cmap=mpl.cm.plasma,norm=norm)\n","cbar = fig.colorbar(sm,ax=axs[0],pad=.01)\n","cbar.set_label(r'Scaling factor')\n","\n","# axis aesthetics\n","axs[0].set(xlabel='Hidden state',xticks=range(0,len(hs_pure),2),xticklabels=xlabels[::2],xlim=[-.5,len(hs_pure)-.5],\n","           ylabel='Matrix difference norm',title='Norm of differences in lines')\n","\n","\n","# show an image of the same data\n","h = axs[1].imshow(layer_norms.T,aspect='auto',cmap=mpl.cm.hot,vmin=0,vmax=layer_norms.max()*.7,extent=[0,len(hs_pure),scale_factors[0],scale_factors[-1]],origin='lower')\n","axs[1].set(xlabel='Hidden state',xticks=range(1,len(hs_pure),2),xticklabels=xlabels[1::2],\n","           ylabel='Scaling factor',title='Norm of differences in an image')\n","fig.colorbar(h,ax=axs[1],pad=.01,label='Norm of $\\Delta$')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"jnq9Q3JjHW6q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"vpI7VE0PHWyl"},"execution_count":null,"outputs":[]}]}