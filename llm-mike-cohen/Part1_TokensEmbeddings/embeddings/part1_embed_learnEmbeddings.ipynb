{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n",
        "|-|:-:|\n",
        "|<h2>Part 1:</h2>|<h1>Tokenizations and embeddings<h1>|\n",
        "|<h2>Section:</h2>|<h1>Embedding spaces<h1>|\n",
        "|<h2>Lecture:</h2>|<h1><b>Multiple videos on learning embeddings<b></h1>|\n",
        "\n",
        "<br>\n",
        "\n",
        "<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n",
        "<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">udemy.com/course/dullms_x/?couponCode=202508</a></h5>\n",
        "<i>Using the code without the course may lead to confusion or errors.</i>"
      ],
      "metadata": {
        "id": "4UImGHr167rz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4yt0kA6wtGu"
      },
      "outputs": [],
      "source": [
        "# typical libraries...\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "\n",
        "# for importing and working with texts\n",
        "import requests\n",
        "import re\n",
        "import string\n",
        "\n",
        "# pytorch stuff\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "!pip install torchinfo # not installed by default in colab\n",
        "from torchinfo import summary\n",
        "\n",
        "import matplotlib_inline.backend_inline\n",
        "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F0_NnImhx-Tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Code below is for video \"Create a data loader to train a model\"**"
      ],
      "metadata": {
        "id": "Cj0Z4gaX04p7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MBfV3Iaq082j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import text and create dictionary"
      ],
      "metadata": {
        "id": "tNMIerWSxqQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get raw text from internet (The Time Machine... yeah I use it a lot :P  )\n",
        "text = requests.get('https://www.gutenberg.org/files/35/35-0.txt').text\n",
        "# character strings to replace with space\n",
        "strings2replace = [ '\\r\\n\\r\\nâ\\x80\\x9c','â\\x80\\x9c','â\\x80\\x9d','\\r\\n','â\\x80\\x94','â\\x80\\x99','â\\x80\\x98','_', ]\n",
        "\n",
        "# use regular expression (re) to replace those strings with space\n",
        "for str2match in strings2replace:\n",
        "  text = re.compile(r'%s'%str2match).sub(' ',text)\n",
        "\n",
        "# remove non-ASCII characters and numbers, and make lower-case\n",
        "text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
        "text = re.sub('\\d+','',text).lower()\n",
        "\n",
        "# split into words with >1 letter\n",
        "words = re.split(f'[{string.punctuation}\\s]+',text)\n",
        "words = [item.strip() for item in words if item.strip()]\n",
        "words = [item for item in words if len(item)>1]\n",
        "\n",
        "# create the vocabulary (lexicon)\n",
        "vocab  = sorted(set(words))\n",
        "nWords = len(words)\n",
        "nVocab = len(vocab)\n",
        "\n",
        "# encoder/decoder look-up-tables (as python dictionaries)\n",
        "word2idx = {w:i for i,w in enumerate(vocab)}\n",
        "idx2word = {i:w for i,w in enumerate(vocab)}\n",
        "\n",
        "# show a few keys in the dictionary\n",
        "print(f'The book contains {nWords:,} words, {nVocab:,} of which are unique and comprise the vocab.')\n",
        "print(f'\\n\\nFirst 10 vocab words:\\n',list(word2idx.keys())[:10])"
      ],
      "metadata": {
        "id": "EPRfkKgHLEsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9_TCDyH2yCkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters for dataset\n",
        "context_length = 8 # context length\n",
        "stride = 2 # skipping\n",
        "\n",
        "# initialize\n",
        "inputs  = []\n",
        "targets = []\n",
        "\n",
        "# overlapping sequences of context_length\n",
        "for i in range(0,nWords-context_length,stride):\n",
        "\n",
        "  # get a few words\n",
        "  in_seq   = words[i  : i+context_length  ]\n",
        "  targ_seq = words[i+1: i+context_length+1]\n",
        "\n",
        "  # append to the lists\n",
        "  inputs.append([word2idx[w] for w in in_seq])\n",
        "  targets.append([word2idx[w] for w in targ_seq])\n",
        "\n",
        "print(inputs[123])\n",
        "print(targets[123])"
      ],
      "metadata": {
        "id": "ra0shrASyCgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a closer look:\n",
        "print('Inputs: ',inputs[4])\n",
        "print('Targets:',targets[4])\n",
        "print('')\n",
        "print('Inputs :',inputs[5])\n",
        "print('Targets:',targets[5])\n",
        "# this is what we need, although we need it in torch Dataset/DataLoader format"
      ],
      "metadata": {
        "id": "gwuxQsr8yCc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we need each list to be a tensor\n",
        "torch.tensor(inputs[4])"
      ],
      "metadata": {
        "id": "neAkNSsXyCZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j8T-gDu-ymvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a class for a dataset object"
      ],
      "metadata": {
        "id": "x6leLgJyymzV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a class for a dataset\n",
        "class WordDataset(Dataset):\n",
        "  def __init__(self, text, word2idx, context_length=8, stride=4):\n",
        "\n",
        "    # initialize\n",
        "    self.inputs  = []\n",
        "    self.targets = []\n",
        "    self.word2idx = word2idx  # stored locally in the object\n",
        "\n",
        "    # overlapping sequences of context_length\n",
        "    for i in range(0,len(text)-context_length,stride):\n",
        "\n",
        "      # get a few words\n",
        "      in_seq   = text[i : i+context_length]\n",
        "      targ_seq = text[i+1 : i+context_length+1]\n",
        "\n",
        "      # append to the lists\n",
        "      self.inputs.append(torch.tensor([word2idx[w] for w in in_seq]))\n",
        "      self.targets.append(torch.tensor([word2idx[w] for w in targ_seq]))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.inputs)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.inputs[idx], self.targets[idx]\n",
        "\n",
        "\n",
        "# create an instance!\n",
        "context_length = 6 # context length\n",
        "stride = 3 # skipping over tokens\n",
        "text_dataset = WordDataset(words,word2idx,context_length,stride)\n",
        "\n",
        "text_dataset[4]"
      ],
      "metadata": {
        "id": "J4NctFIlGyhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m5UdAWBRz4BA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## And a dataloader for training"
      ],
      "metadata": {
        "id": "0UlFizlrz3-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# also need a dataloader\n",
        "dataloader = DataLoader(\n",
        "                text_dataset,\n",
        "                batch_size = 32, # 2 for looking; 32 for training\n",
        "                shuffle    = True,\n",
        "                drop_last  = True\n",
        "            )\n",
        "\n",
        "# let's have a look at the indices\n",
        "X,y = next(iter(dataloader))\n",
        "print('Inputs:')\n",
        "print(X), print('')\n",
        "\n",
        "print('Targets:')\n",
        "print(y), print('\\n\\n\\n')\n",
        "\n",
        "# and the words\n",
        "print('Inputs in words (first batch):')\n",
        "print([idx2word[item.item()] for item in X[0]])\n",
        "print('')\n",
        "\n",
        "print('Targets in words (first batch):')\n",
        "print([idx2word[item.item()] for item in y[0]])"
      ],
      "metadata": {
        "id": "tfRohf_XGykQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "euxnrW7Vym2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Code below is for video \"Build a model to learn the embeddings\"**"
      ],
      "metadata": {
        "id": "5GX24waQyCVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# exploring dimensionality based on vocab sizes\n",
        "\n",
        "# vocab sizes\n",
        "N = np.logspace(np.log10(1000),np.log10(100000),23)\n",
        "\n",
        "# heuristic for non-LLM models like word2vec or glove:\n",
        "embdim = np.sqrt(N)\n",
        "\n",
        "# parameters for GPT2\n",
        "gpt2dims = [ 50257,768 ]\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "\n",
        "# heuristic line\n",
        "plt.plot(N,embdim,'ks-',markersize=8,markerfacecolor=[.9,.7,.7],label=r'$s = \\sqrt{N}$')\n",
        "\n",
        "# expected embedding dim for GPT2\n",
        "plt.plot([gpt2dims[0],gpt2dims[0]],[0,np.sqrt(gpt2dims[0])],'k--',linewidth=1,label='Expected GPT2')\n",
        "plt.plot([0,gpt2dims[0]],[np.sqrt(gpt2dims[0]),np.sqrt(gpt2dims[0])],'k--',linewidth=1)\n",
        "\n",
        "# actual GPT2 embedding\n",
        "plt.plot([gpt2dims[0],gpt2dims[0]],[0,gpt2dims[1]],'b:',linewidth=1,label='Actual GPT2')\n",
        "plt.plot([0,gpt2dims[0]],[gpt2dims[1],gpt2dims[1]],'b:',linewidth=1)\n",
        "\n",
        "plt.gca().set(xlabel='Vocab size',ylabel='Embeddings dimensions',\n",
        "              xlim=[-100,N[-1]+2000],ylim=[0,None])\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4fJdqoMgHrV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l9_wXkjWHrQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create and explore an embedding layer"
      ],
      "metadata": {
        "id": "mDvqf1Ttd3Uw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dimensionality of embedding space (arbitrarily set to 100)\n",
        "embeddingDimension = 100\n",
        "\n",
        "# create a random embedding\n",
        "embedding_layer = nn.Embedding(nVocab,embeddingDimension)\n",
        "\n",
        "# let's see its size\n",
        "embedding_layer.weight.shape"
      ],
      "metadata": {
        "id": "NOImevDUd5hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# what does it look like?\n",
        "\n",
        "_,axs = plt.subplots(1,2,figsize=(12,4))\n",
        "axs[0].imshow(embedding_layer.weight.detach().T,aspect='auto',vmin=-1,vmax=1)\n",
        "axs[0].set(ylabel='Embedding dimension',xlabel='Token index',title='Entire embedding matrix')\n",
        "\n",
        "# pick a word at random\n",
        "aRandomWord = np.random.choice(vocab)\n",
        "\n",
        "# plot its embedding\n",
        "axs[1].plot(embedding_layer.weight.detach()[word2idx[aRandomWord],:],'ks',markerfacecolor=[.7,.9,.7])\n",
        "axs[0].axvline(word2idx[aRandomWord],color='w',linestyle='--')\n",
        "axs[1].set(xlabel='Embedding dimension',ylabel='Weight value',title=f'Embedding for \"{aRandomWord}\" (idx = {word2idx[aRandomWord]})')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KX77I315d3XZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "og0TEkjPReRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# embeddings for closely related words\n",
        "word1 = 'time'\n",
        "word2 = 'machine'\n",
        "\n",
        "# their embeddings\n",
        "embed1 = embedding_layer.weight.detach()[word2idx[word1],:]\n",
        "embed2 = embedding_layer.weight.detach()[word2idx[word2],:]\n",
        "\n",
        "# cosine similiarity between them\n",
        "cosSim = torch.dot(embed1,embed2)/(torch.norm(embed1)*torch.norm(embed2))\n",
        "\n",
        "# vizualize\n",
        "plt.plot(embed1,embed2,'ks',markerfacecolor=[.7,.9,.7],alpha=.6)\n",
        "plt.gca().set(xlabel=f'Embedding for \"{word1}\"',ylabel=f'Embedding for \"{word2}\"',\n",
        "              title=f'Cosine similarity: {cosSim:.3f}')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IMv9FiDAiKBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g-1l0hJL0-nn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the model"
      ],
      "metadata": {
        "id": "tfIHOi-KHXMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbeddingModel(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, context_size):\n",
        "    super(EmbeddingModel, self).__init__()\n",
        "\n",
        "    # embedding layer\n",
        "    self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "    # linear layers\n",
        "    self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
        "    self.linear2 = nn.Linear(128, vocab_size)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "\n",
        "    # extract and flatten embeddings [batch_size, context_size * embedding_dim]\n",
        "    embeds = self.embeddings(inputs).view(inputs.shape[0],-1)\n",
        "\n",
        "    # fully connected layers\n",
        "    out = F.relu(self.linear1(embeds))\n",
        "    out = self.linear2(out)\n",
        "\n",
        "    # log softmax for classification (note: NLLLoss expects logprobs as inputs)\n",
        "    log_probs = F.log_softmax(out, dim=1)\n",
        "    return log_probs\n",
        "\n",
        "\n",
        "# create a model instance!\n",
        "model = EmbeddingModel(vocab_size=nVocab, embedding_dim=embeddingDimension, context_size=context_length)\n",
        "print(model)\n",
        "\n",
        "# apply Xavier weight distribution\n",
        "for param in model.parameters():\n",
        "  if param.dim()>1: # also excludes biases\n",
        "    nn.init.xavier_normal_(param)"
      ],
      "metadata": {
        "id": "--fKDPmYns8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's test the model\n",
        "\n",
        "X,y = next(iter(dataloader))\n",
        "modelOut = model(X)\n",
        "\n",
        "print('Input to model:')\n",
        "print(X), print('')\n",
        "\n",
        "print(f'Output from model (size: {list(modelOut.detach().shape)}):')\n",
        "print(modelOut)"
      ],
      "metadata": {
        "id": "xjQ34R6Lskc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# log soft-max output:\n",
        "print(modelOut.detach()[0])\n",
        "print('')\n",
        "\n",
        "# shouldn't the sum be 1?\n",
        "print(f'Log softmax sum = {modelOut.detach()[0].sum():.3f}')\n",
        "\n",
        "# ah, it's *log* softmax :D\n",
        "print(f'exp(log(softmax)) sum = {torch.exp(modelOut.detach()[0]).sum():.3f}')"
      ],
      "metadata": {
        "id": "hXgPuzyFsvdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find the word with the highest probability\n",
        "print('Model input:')\n",
        "print([idx2word[w.item()] for w in X[0]])\n",
        "print('')\n",
        "\n",
        "print('Model output:')\n",
        "print(idx2word[modelOut[0].argmax().item()])"
      ],
      "metadata": {
        "id": "bgOriLFHt3vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(modelOut[0].detach(),'o');"
      ],
      "metadata": {
        "id": "W8E_NyL98Jcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Have the model generate text"
      ],
      "metadata": {
        "id": "fSpQM4vn8Jzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# grab some data from the loader\n",
        "X,y = next(iter(dataloader))\n",
        "\n",
        "print('First input:')\n",
        "print(' '.join([idx2word[w.item()] for w in X[0]]))\n",
        "print('\\nSubsequent inputs:')\n",
        "\n",
        "# text generation\n",
        "for _ in range(context_length):\n",
        "\n",
        "  # get output for this input\n",
        "  Y = model(X)\n",
        "\n",
        "  # pick the most likely next word\n",
        "  nextWord = Y[0].argmax().item()\n",
        "\n",
        "  # create new input for the next iteration (word)\n",
        "  X[0] = torch.concatenate((X[0][1:],torch.tensor([nextWord])))\n",
        "\n",
        "  # print out the generated text so far\n",
        "  print(' '.join([idx2word[w.item()] for w in X[0]]))"
      ],
      "metadata": {
        "id": "RrBSScdw3RQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uWl8IMwA3RKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How big is our model?"
      ],
      "metadata": {
        "id": "0LmtGo2q8_gi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# summary of model and parameters\n",
        "summary(model, input_data=X, col_names=['input_size','output_size','num_params'])"
      ],
      "metadata": {
        "id": "7Ct2HcS0HYNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vJ1wUpj00-ko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Adz4XYKW0-hg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Code below is for video \"Train and evaluate the model\"**"
      ],
      "metadata": {
        "id": "7a54n_yx9S_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we'll use the GPU for speed\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')"
      ],
      "metadata": {
        "id": "c4Vvuq-p0-b8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a fresh model instance\n",
        "model = EmbeddingModel(vocab_size=nVocab, embedding_dim=embeddingDimension, context_size=context_length)\n",
        "\n",
        "# with Xavier weight distribution\n",
        "for param in model.parameters():\n",
        "  if param.dim()>1: nn.init.xavier_normal_(param)\n",
        "\n",
        "\n",
        "# and move it to the GPU\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "O1Ulfu-N53Wp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the loss and optimizer functions\n",
        "loss_function = nn.NLLLoss().to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=.001, weight_decay=.01)"
      ],
      "metadata": {
        "id": "3hlpVjic6oVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# quick test for errors and sanity-check the output matrix sizes\n",
        "X,y = next(iter(dataloader))\n",
        "X,y = X.to(device), y.to(device)\n",
        "\n",
        "# forward pass\n",
        "modelOutput = model(X)\n",
        "\n",
        "# check the sizes\n",
        "print(f'Model input is of size: {X.shape}')\n",
        "print(f'Target output is of size: {y.shape}')\n",
        "print(f'Model output is of size: {modelOutput.shape}')\n",
        "\n",
        "# loss function\n",
        "loss = loss_function(modelOutput,y[:,-1])\n",
        "print(f'\\nLoss:')\n",
        "loss"
      ],
      "metadata": {
        "id": "-B-QSF6xzY8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract a copy of the pretrained embedding weights for comparison later\n",
        "pretrained_embeddings = model.embeddings.weight.detach().cpu().clone()"
      ],
      "metadata": {
        "id": "jzlgZNND_sgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reminder: use batchsize=32 in data loader ;)"
      ],
      "metadata": {
        "id": "_uGwrosX-s_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C-XuGYYZ0oBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now train the model!"
      ],
      "metadata": {
        "id": "gICE2otK-s89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trainTheModel(model,num_epochs=25):\n",
        "\n",
        "  # initialize losses\n",
        "  total_loss = np.zeros(num_epochs)\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "\n",
        "    # initialize\n",
        "    epoch_loss = 0\n",
        "\n",
        "    # loop over batches in the data loader\n",
        "    for X,y in dataloader:\n",
        "\n",
        "      # move data to GPU\n",
        "      X,y = X.to(device), y.to(device)\n",
        "\n",
        "      # clear previous gradients\n",
        "      model.zero_grad()\n",
        "\n",
        "      # forward pass\n",
        "      log_probs = model(X)\n",
        "\n",
        "      # calculate the losses from the final target word\n",
        "      loss = loss_function(log_probs,y[:,-1])\n",
        "\n",
        "      # backprop\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # sum the per-epoch losses\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "    # scale by the number of tokens in this dataloader\n",
        "    total_loss[epoch] = epoch_loss / len(dataloader.dataset)\n",
        "\n",
        "    # update our progress :)\n",
        "    print(f'  Finished epoch {epoch+1} with loss {epoch_loss / len(dataloader.dataset):.4f}')\n",
        "\n",
        "  # output the model and the losses\n",
        "  return model,total_loss"
      ],
      "metadata": {
        "id": "WUYuqpThHZL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model!\n",
        "model,total_loss = trainTheModel(model) # using default 25 epochs\n",
        "\n",
        "# plot the losses\n",
        "plt.figure(figsize=(10,3))\n",
        "plt.plot(total_loss,'ks-',markerfacecolor='w',markersize=8)\n",
        "plt.gca().set(xlabel='Epoch',ylabel='Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5XdjwacoHZOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get a copy of the trained weights\n",
        "postrained_embeddings = model.embeddings.weight.detach().cpu().clone()"
      ],
      "metadata": {
        "id": "VqWnA1sj_pJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3ov_EOYK014t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7DWGuVGoWmue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "95pu02kuWmq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zjm2u2uqWmlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yDwHQPFFWmiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iVP5sz_SWmfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plenty of empty space so you won't look by accident :P"
      ],
      "metadata": {
        "id": "xmsjk7-BWgMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gDZpLzQZWgJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1MeICytWWgGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AEVUOJoyWgEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bilpY5XwWgBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CItqR8UGWf-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8o-ytlcAWf5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vzy0HzK9Wf2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w9lvsWKPDgrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Code below is for video \"CodeChallenge: How the embeddings change\"**"
      ],
      "metadata": {
        "id": "jXIcg6-WDjyt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 1: distributions of embeddings"
      ],
      "metadata": {
        "id": "c3g-359cEEjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# histograms via numpy\n",
        "yPre,xPre = np.histogram(pretrained_embeddings.flatten(),bins=50)\n",
        "yPst,xPst = np.histogram(postrained_embeddings.flatten(),bins=50)\n",
        "\n",
        "# recalculate x values as bin centers\n",
        "xPre = (xPre[1:]+xPre[:-1]) / 2\n",
        "xPst = (xPst[1:]+xPst[:-1]) / 2\n",
        "\n",
        "# and plot\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.bar(xPst,yPst,width=xPst[1]-xPst[0],color=[.7,.9,.7,.7],edgecolor=[.3,.6,0,.4],label='POSTtrain')\n",
        "plt.bar(xPre,yPre,width=xPre[1]-xPre[0],color=[.9,.7,.7,.3],edgecolor=[.6,0,.3,.4],label='PREtrain')\n",
        "\n",
        "plt.gca().set(xlabel='Weight value',ylabel='Count',title='Distributions of embedding weights')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tUg89F5iEFaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GRWkVmfJEFX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 2: Embeddings vectors for a random word"
      ],
      "metadata": {
        "id": "Pe1U-JRpHZnX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pick a word at random\n",
        "aRandomWord = np.random.choice(vocab)\n",
        "randWord_idx = word2idx[aRandomWord]\n",
        "\n",
        "# extract its embeddings vectors\n",
        "pre_ev = pretrained_embeddings[randWord_idx,:]\n",
        "pst_ev = postrained_embeddings[randWord_idx,:]\n",
        "\n",
        "\n",
        "\n",
        "_,axs = plt.subplots(2,2,figsize=(10,7))\n",
        "\n",
        "# the pretrainined embeddings\n",
        "axs[0,0].imshow(pretrained_embeddings.T,aspect='auto',vmin=-.2,vmax=.2)\n",
        "axs[0,0].set(ylabel='Embedding dimension',xlabel='Token index',title='PREtrain embedding matrix')\n",
        "\n",
        "# the post-trainined embeddings\n",
        "axs[0,1].imshow(postrained_embeddings.T,aspect='auto',vmin=-.2,vmax=.2)\n",
        "axs[0,1].set(ylabel='Embedding dimension',xlabel='Token index',title='POSTtrain embedding matrix')\n",
        "\n",
        "\n",
        "axs[0,0].axvline(randWord_idx,linestyle='--',color=[.8,.8,.8])\n",
        "axs[0,1].axvline(randWord_idx,linestyle='--',color=[.8,.8,.8])\n",
        "\n",
        "# plot its embedding\n",
        "axs[1,0].plot(pre_ev,'ks-',markerfacecolor=[.7,.9,.7],label='PREtrain')\n",
        "axs[1,0].plot(pst_ev,'ko-',markerfacecolor=[.9,.7,.7],label='POSTtrain')\n",
        "axs[1,0].set(xlabel='Embedding dimension',ylabel='Weight value',title=f'\"{aRandomWord}\" embedding (idx={randWord_idx})')\n",
        "axs[1,0].legend(fontsize=8)\n",
        "\n",
        "# how it changed\n",
        "axlim = max(abs(pre_ev).max(),abs(pst_ev).max()) * 1.1 # equal axis limits\n",
        "axs[1,1].plot(pre_ev,pst_ev,'ks',markerfacecolor=[.9,.7,.9])\n",
        "axs[1,1].set(xlim=[-axlim,axlim],ylim=[-axlim,axlim],xlabel='PREtrain embedding',\n",
        "             ylabel='POSTtrain embedding',title='Change in embedding')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6dc3qZeSGyq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lVduMOm8CroI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 3: Time Machine embeddings"
      ],
      "metadata": {
        "id": "lUZbdF41Creo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# embeddings for closely related words\n",
        "word1 = 'time'\n",
        "word2 = 'machine'\n",
        "\n",
        "# their embeddings\n",
        "embed1pre = pretrained_embeddings[word2idx[word1],:]\n",
        "embed2pre = pretrained_embeddings[word2idx[word2],:]\n",
        "embed1pst = postrained_embeddings[word2idx[word1],:]\n",
        "embed2pst = postrained_embeddings[word2idx[word2],:]\n",
        "\n",
        "# cosine similarity between them\n",
        "cosSim_pre = F.cosine_similarity(embed1pre.unsqueeze(dim=0),embed2pre.view(1,-1))\n",
        "cosSim_pst = nn.functional.cosine_similarity(embed1pst.unsqueeze(dim=0),embed2pst.view(1,-1))\n",
        "\n",
        "\n",
        "# vizualize\n",
        "_,axs = plt.subplots(1,2,figsize=(10,4))\n",
        "\n",
        "axlim = torch.cat((abs(embed1pre),abs(embed2pre),abs(embed1pst),abs(embed2pst))).max() * 1.1\n",
        "axs[0].plot(embed1pre,embed2pre,'ks',markerfacecolor=[.9,.7,.7],alpha=.6)\n",
        "axs[0].set(xlim=[-axlim,axlim],ylim=[-axlim,axlim],xlabel=f'\"{word1}\" embedding',\n",
        "           ylabel=f'\"{word2}\" embedding',title=f'Cosine similarity PREtrain: {cosSim_pre.item():.3f}')\n",
        "\n",
        "axs[1].plot(embed1pst,embed2pst,'ko',markerfacecolor=[.7,.9,.7])\n",
        "axs[1].set(xlim=[-axlim,axlim],ylim=[-axlim,axlim],xlabel=f'\"{word1}\" embedding',\n",
        "           ylabel=f'\"{word2}\" embedding',title=f'Cosine similarity POSTtrain: {cosSim_pst.item():.3f}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "V9BQM5ZOGyuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cosine similarity manually\n",
        "num = torch.dot(embed1pst,embed2pst)\n",
        "den = torch.norm(embed1pst)*torch.norm(embed2pst)\n",
        "cs_man = num / den\n",
        "\n",
        "# and via pytorch\n",
        "cs_pyt = F.cosine_similarity(embed2pst.unsqueeze(dim=0),embed1pst.view(1,-1))\n",
        "\n",
        "print(f'Cosine similarity from numpy: {cs_man:.4f}')\n",
        "print(f'Cosine similarity from torch: {cs_pyt.item():.4f}')"
      ],
      "metadata": {
        "id": "KGGhvH2aJUQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R_CHZ4j4hAzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vuxujljI9XoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Code below is for video \"CodeChallenge: How stable are embeddings?\"**"
      ],
      "metadata": {
        "id": "ePq4WtnDTxhN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 1: New training, different weights"
      ],
      "metadata": {
        "id": "ntf01OMW9XlR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# number of repetitions (new models) and epochs\n",
        "numRepetitions = 10\n",
        "numEpochs = 16\n",
        "\n",
        "# initializations\n",
        "lossesMatrix = np.zeros((numRepetitions,numEpochs))\n",
        "embeddingsMats = []\n",
        "\n",
        "# loop over repetitions\n",
        "for repi in range(numRepetitions):\n",
        "\n",
        "  # create a new model\n",
        "  model = EmbeddingModel(vocab_size=nVocab, embedding_dim=embeddingDimension, context_size=context_length)\n",
        "  model = model.to(device)\n",
        "  for param in model.parameters():\n",
        "    if param.dim()>1: nn.init.xavier_normal_(param)\n",
        "\n",
        "  # need to recreate the optimizer b/c it retains gradient/overhead info\n",
        "  optimizer = torch.optim.AdamW(model.parameters(), lr=.001, weight_decay=.01)\n",
        "\n",
        "  # train the model\n",
        "  print(f'** Running repetition {repi+1}/{numRepetitions} **')\n",
        "  model,total_loss = trainTheModel(model,numEpochs)\n",
        "  print('\\n')\n",
        "\n",
        "  # get its losses\n",
        "  lossesMatrix[repi,:] = total_loss\n",
        "\n",
        "  # extract the embedding matrix\n",
        "  embeddingsMats.append( model.embeddings.weight.detach().cpu() )"
      ],
      "metadata": {
        "id": "96wla6_U9XiT",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6sbv03nlsRx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the losses\n",
        "plt.figure(figsize=(10,4))\n",
        "\n",
        "# in a for-loop to get different colors\n",
        "for i in range(numRepetitions):\n",
        "  plt.plot(lossesMatrix[i,:],'s-',linewidth=2,color=mpl.cm.plasma(i/numRepetitions),label=f'Rep. {i+1}')\n",
        "\n",
        "plt.legend()\n",
        "plt.gca().set(xticks=range(numEpochs),xlabel='Training epochs',ylabel='Losses')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "U82fpG6o9XcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xfv5zY3igtFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 2: Consistency of embedding vectors"
      ],
      "metadata": {
        "id": "9ErfcPCrkQd4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_,axs = plt.subplots(3,2,figsize=(14,8))\n",
        "\n",
        "# random words\n",
        "randWords = np.random.choice(vocab,size=np.prod(axs.shape))\n",
        "\n",
        "# but what do individual embeddings look like?\n",
        "for wordi,ax in enumerate(axs.flatten()):\n",
        "\n",
        "  # index of this random word\n",
        "  randWord_idx = word2idx[randWords[wordi]]\n",
        "\n",
        "  # loop over the repetitions\n",
        "  for repi in range(numRepetitions):\n",
        "\n",
        "    # draw lines for embeddings in each repetition\n",
        "    ax.plot(embeddingsMats[repi][randWord_idx,:])\n",
        "\n",
        "  # title of this subplot\n",
        "  ax.set_title(f'\"{randWords[wordi]}\" embedding',fontsize=14)\n",
        "\n",
        "\n",
        "# final adjustments\n",
        "for a in axs.flatten(): a.set(xticks=[],yticks=[],xlim=[-1,embeddingDimension])\n",
        "ax.set(xlabel='Embedding dimension',ylabel='Weight value')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4EIevtQ19XTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8LfgU3voiisf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 3: Cosine similarity for selected word pairs"
      ],
      "metadata": {
        "id": "-fHmrYfBiipo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pick three words\n",
        "word1 = 'time'\n",
        "word2 = 'machine'\n",
        "word3 = 'she'\n",
        "\n",
        "# vector of cosine similarity for each repetition\n",
        "cossim = np.zeros((numRepetitions,3))\n",
        "\n",
        "# and the for-loop!\n",
        "for repi in range(numRepetitions):\n",
        "\n",
        "  # their embeddings\n",
        "  e1 = embeddingsMats[repi][word2idx[word1],:]\n",
        "  e2 = embeddingsMats[repi][word2idx[word2],:]\n",
        "  e3 = embeddingsMats[repi][word2idx[word3],:]\n",
        "\n",
        "  # cosine similarity between each pair\n",
        "  cossim[repi,0] = nn.functional.cosine_similarity(e1,e2.view(1,-1)).item()\n",
        "  cossim[repi,1] = nn.functional.cosine_similarity(e1,e3.view(1,-1)).item()\n",
        "  cossim[repi,2] = nn.functional.cosine_similarity(e2,e3.view(1,-1)).item()\n",
        "\n",
        "\n",
        "# the plot\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(cossim[:,0],'ks',markerfacecolor=[.9,.7,.7],markersize=12,label=f'\"{word1}\" and \"{word2}\"')\n",
        "plt.plot(cossim[:,1],'ko',markerfacecolor=[.7,.8,.7],markersize=12,label=f'\"{word1}\" and \"{word3}\"')\n",
        "plt.plot(cossim[:,2],'k^',markerfacecolor=[.7,.7,.8],markersize=12,label=f'\"{word2}\" and \"{word3}\"')\n",
        "\n",
        "plt.axhline(0,color=[.7,.7,.7],linestyle='--',zorder=-10)\n",
        "plt.gca().set(xticks=range(numRepetitions),ylim=[-.4,.6],\n",
        "              xlabel='Training repetition',ylabel='Cosine similarity',title='Cosine similarities')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wumkmXBp9XWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_0VV__Hd9XQn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}