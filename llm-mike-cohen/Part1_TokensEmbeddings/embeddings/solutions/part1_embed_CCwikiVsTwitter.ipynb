{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n",
        "|-|:-:|\n",
        "|<h2>Part 1:</h2>|<h1>Tokenizations and embeddings<h1>|\n",
        "|<h2>Section:</h2>|<h1>Embedding spaces<h1>|\n",
        "|<h2>Lecture:</h2>|<h1><b>CodeChallenge: Wikipedia vs. Twitter embeddings<b></h1>|\n",
        "\n",
        "<br>\n",
        "\n",
        "<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n",
        "<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">udemy.com/course/dullms_x/?couponCode=202508</a></h5>\n",
        "<i>Using the code without the course may lead to confusion or errors.</i>"
      ],
      "metadata": {
        "id": "8Z06zLxr6vIl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2l85Wel2qa04"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "\n",
        "# svg figure format\n",
        "import matplotlib_inline.backend_inline\n",
        "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KsGto4rz1zvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 1: Download and inspect the models"
      ],
      "metadata": {
        "id": "5onBwtyv1zsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: If you get errors importing, run the following !pip... line,\n",
        "# then restart your session (from Runtime menu) and comment out the pip line.\n",
        "# !pip install gensim\n",
        "\n",
        "import gensim.downloader as api\n",
        "\n",
        "# download the wikipedia and twitter models\n",
        "wiki = api.load('glove-wiki-gigaword-50')\n",
        "twit = api.load('glove-twitter-50')"
      ],
      "metadata": {
        "id": "xh3PJNtPqnPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir(twit)"
      ],
      "metadata": {
        "id": "_ac3JrC4qnMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A-FwRwHW1387"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding matrix dimensions\n",
        "print(f'Wikipedia model has {wiki.vectors.shape[0]:,} words and {wiki.vectors.shape[1]} embedding dimensions.')\n",
        "print(f'Twitter model has {twit.vectors.shape[0]:,} words and {twit.vectors.shape[1]} embedding dimensions.')"
      ],
      "metadata": {
        "id": "I6z0HLDKq67A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LtCRoY2mqnJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 2: Visualize the embeddings for one word"
      ],
      "metadata": {
        "id": "nsIJFUOgqnGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "targetword = 'table'\n",
        "\n",
        "_,axs = plt.subplots(1,2,figsize=(12,4.5))\n",
        "axs[0].plot(wiki[targetword],'ks',markerfacecolor=[.7,.7,.9],markersize=8,label='Wikipedia')\n",
        "axs[0].plot(twit[targetword],'ko',markerfacecolor=[.7,.9,.7],markersize=8,label='Twitter')\n",
        "axs[0].set(xlabel='Dimension',ylabel='Value',title=f'Embeddings for \"{targetword}\"')\n",
        "axs[0].legend()\n",
        "\n",
        "axs[1].plot(wiki[targetword],twit[targetword],'k^',markerfacecolor=[.9,.7,.7],markersize=8)\n",
        "axs[1].set(xlabel='Wiki embedding',ylabel='Twitter embedding',title=f'Embeddings for \"{targetword}\"')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rJQ8cnIeyAKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nqCB1EAmqnDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 3: Embeddings for word pairs within each model"
      ],
      "metadata": {
        "id": "-Qs7-sWLqnAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# word pair\n",
        "word1 = 'table'\n",
        "word2 = 'chair'\n",
        "\n",
        "# scatter plot for wiki\n",
        "_,axs = plt.subplots(1,2,figsize=(12,4.5))\n",
        "axs[0].plot(wiki[word1],wiki[word2],'ks',markersize=9,markerfacecolor=[.9,.7,.7])\n",
        "axs[0].set(xlabel=f'Embedding for \"{word1}\"',ylabel=f'Embedding for \"{word2}\"',\n",
        "           title=f'WIKI (Cosine similarity: {wiki.similarity(word1,word2):.3f})')\n",
        "\n",
        "\n",
        "# scatter plot for twitter\n",
        "axs[1].plot(twit[word1],twit[word2],'ko',markersize=9,markerfacecolor=[.7,.9,.7])\n",
        "axs[1].set(xlabel=f'Embedding for \"{word1}\"',ylabel=f'Embedding for \"{word2}\"',\n",
        "           title=f'TWITTER (Cosine similarity: {twit.similarity(word1,word2):.3f})')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0FchbjGsy5XG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pSNWY7BMy5Z3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 4: Similar words within each model"
      ],
      "metadata": {
        "id": "zD0NV-mA2DAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('10 words most similar to \"battery\" in wiki:')\n",
        "for w,cs in wiki.most_similar('battery'):\n",
        "  print(f' {w:>15} with similarity {cs:.4f}')\n",
        "\n",
        "print('\\nAnd in twitter:')\n",
        "for w,cs in twit.most_similar('battery'):\n",
        "  print(f' {w:>15} with similarity {cs:.4f}')"
      ],
      "metadata": {
        "id": "0H2lzMaEy5ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mnMsFM1Hqm9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 5: foxes and dogs"
      ],
      "metadata": {
        "id": "_pAAvm46NLVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'The quick brown fox jumps over the lazy dog'\n",
        "\n",
        "import re\n",
        "words = re.split('\\\\s',text)#.lower())\n",
        "\n",
        "# index sequence in the two embeddings\n",
        "wiki_idx = [wiki.key_to_index[w] if w in wiki.key_to_index else np.Inf for w in words ]\n",
        "twit_idx = [twit.key_to_index[w] if w in twit.key_to_index else np.Inf for w in words ]\n",
        "\n",
        "print(' Word |  Wiki | Twitter')\n",
        "print('-'*23)\n",
        "for o,w,t in zip(words,wiki_idx,twit_idx):\n",
        "  print(f'{o:>5} | {w:>5} | {t:>5}')"
      ],
      "metadata": {
        "id": "u5ed8-opIM-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get all unique inter-word similarities\n",
        "\n",
        "plt.figure(figsize=(9,7))\n",
        "\n",
        "# start range at 0 or 1?\n",
        "for i in range(0,len(words)):\n",
        "  for j in range(i+1,len(words)):\n",
        "\n",
        "    # skip identity\n",
        "    if words[i]==words[j]: continue\n",
        "\n",
        "    # calculate the cosine similarities for the two embeddings\n",
        "    cs_wiki = wiki.similarity(wiki_idx[i],wiki_idx[j])\n",
        "    cs_twit = twit.similarity(twit_idx[i],twit_idx[j])\n",
        "\n",
        "    # calculate the distance to the unity line\n",
        "    v = np.array([cs_wiki,cs_twit])\n",
        "    u = np.array([1,1])\n",
        "    dist = np.linalg.norm(v - (sum(v*u))/(np.linalg.norm(u)**2)*u)\n",
        "\n",
        "    # draw the results at the coordinates\n",
        "    plt.plot(cs_wiki,cs_twit,'ks',markersize=9,markerfacecolor=mpl.cm.plasma(dist*5))\n",
        "\n",
        "    # and write the word pair\n",
        "    plt.text(cs_wiki,cs_twit+.02,f'{words[i]}-{words[j]}',va='bottom',ha='center')\n",
        "\n",
        "\n",
        "\n",
        "# plot the unity line\n",
        "xylims = [.05,.95]\n",
        "plt.plot(xylims,xylims,'--',color=[.4,.4,.4],zorder=-30)\n",
        "\n",
        "# final adjustments\n",
        "plt.gca().set(xlim=xylims,ylim=xylims,xlabel='Wiki inter-word similarities',\n",
        "              ylabel='Twitter inter-word similarities',title='Inter-word similarities')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FmDChKOzIM7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xKPvbC9_IM48"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}