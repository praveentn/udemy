{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n",
        "|-|:-:|\n",
        "|<h2>Part 1:</h2>|<h1>Tokenizations and embeddings<h1>|\n",
        "|<h2>Section:</h2>|<h1>Words to tokens to numbers<h1>|\n",
        "|<h2>Lecture:</h2>|<h1><b>Preparing text for tokenization<b></h1>|\n",
        "\n",
        "<br>\n",
        "\n",
        "<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n",
        "<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">udemy.com/course/dullms_x/?couponCode=202508</a></h5>\n",
        "<i>Using the code without the course may lead to confusion or errors.</i>"
      ],
      "metadata": {
        "id": "EmjZga3A4r5a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwgCppyRKogB"
      },
      "outputs": [],
      "source": [
        "# typical libraries...\n",
        "import numpy as np\n",
        "\n",
        "# for importing and working with texts\n",
        "import requests\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eXrL9iSI4vWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get text from the web"
      ],
      "metadata": {
        "id": "fEFbCZ8FLEu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get raw text from internet\n",
        "book = requests.get('https://www.gutenberg.org/files/35/35-0.txt')\n",
        "\n",
        "# extract just the text and have a look at it\n",
        "text = book.text\n",
        "print(type(text))\n",
        "print(len(text))\n",
        "\n",
        "text[:2000]"
      ],
      "metadata": {
        "id": "EPRfkKgHLEsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# character strings to replace with space\n",
        "strings2replace = [\n",
        "                 '\\r\\n\\r\\nâ\\x80\\x9c', # new paragraph\n",
        "                 'â\\x80\\x9c',         # open quote\n",
        "                 'â\\x80\\x9d',         # close quote\n",
        "                 '\\r\\n',              # new line\n",
        "                 'â\\x80\\x94',         # hyphen\n",
        "                 'â\\x80\\x99',         # single apostrophe\n",
        "                 'â\\x80\\x98',         # single quote\n",
        "                 '_',                 # underscore, used for stressing\n",
        "                 ]\n",
        "\n",
        "# e.g., 'â\\x80\\x9d'.encode('latin1').decode('utf8')\n",
        "\n",
        "# use regular expression (re) to replace those strings with space\n",
        "for str2match in strings2replace:\n",
        "  regexp = re.compile(r'%s'%str2match)\n",
        "  text = regexp.sub(' ',text)\n",
        "\n",
        "# remove non-ASCII characters\n",
        "text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
        "\n",
        "# remove numbers\n",
        "text = re.sub(r'\\d+','',text)\n",
        "\n",
        "# and make everything lower-case\n",
        "text = text.lower()\n",
        "\n",
        "# let's have a look!\n",
        "text[:2000]"
      ],
      "metadata": {
        "id": "FHv-NtW2LEnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WMbx-idzLEj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parse text into words"
      ],
      "metadata": {
        "id": "l9bZigJ-LEg4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split by punctuation\n",
        "import string\n",
        "print(string.punctuation)\n",
        "puncts4re = fr'[{string.punctuation}\\s]+'\n",
        "\n",
        "words = re.split(puncts4re,text)\n",
        "words = [item.strip() for item in words if item.strip()]\n",
        "\n",
        "# remove single-character words\n",
        "words = [item for item in words if len(item)>1]\n",
        "\n",
        "# let's have a look!\n",
        "words[:50]"
      ],
      "metadata": {
        "id": "nuOxaaahLMh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the vocab! (set of unique words)\n",
        "vocab = sorted(set(words))\n",
        "\n",
        "# convenience variables for later\n",
        "nWords = len(words)\n",
        "nLex = len(vocab)\n",
        "\n",
        "print(f'{nWords} words')\n",
        "print(f' {nLex} unique tokens')"
      ],
      "metadata": {
        "id": "rnzenHKZLEZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hJIWEvEeLEW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create token dictionaries and encoder/decoder functions"
      ],
      "metadata": {
        "id": "x7CADnuQLET_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word2idx = {w:i for i,w in enumerate(vocab)}\n",
        "idx2word = {i:w for i,w in enumerate(vocab)}\n",
        "\n",
        "# print out a few\n",
        "for i in list(word2idx.items())[0:10000:87]:\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "Belr9eoCLTcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "esuSuaEgLERc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encoder function (using for-loop instead of list-comp)\n",
        "def encoder(words,encode_dict):\n",
        "\n",
        "  # initialize a vector of numerical indices\n",
        "  idxs = np.zeros(len(words),dtype=int)\n",
        "\n",
        "  # loop through the words and find their token in the vocab\n",
        "  for i,w in enumerate(words):\n",
        "    idxs[i] = encode_dict[w]\n",
        "\n",
        "  # return the indices!\n",
        "  return idxs\n",
        "\n",
        "\n",
        "# also need a decoder function\n",
        "def decoder(idxs,decode_dict):\n",
        "  return ' '.join([decode_dict[i] for i in idxs])\n"
      ],
      "metadata": {
        "id": "2HYTeIawLEOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test the encoder\n",
        "print(encoder(['the','time','machine'],word2idx))\n",
        "\n",
        "# test the decoder\n",
        "print(decoder([1,3,10],idx2word))"
      ],
      "metadata": {
        "id": "93yoreY15Y-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c7jgPRj_cRAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test encode-then-decode\n",
        "\n",
        "# random start location\n",
        "startidx = np.random.choice(nWords)\n",
        "\n",
        "# sequential word indices\n",
        "idxs = np.arange(startidx,startidx+10)\n",
        "\n",
        "print('Word indices:')\n",
        "print(idxs), print('')\n",
        "\n",
        "print('The words:')\n",
        "wordseq = [ words[i] for i in idxs ]\n",
        "print(wordseq), print('')\n",
        "\n",
        "print('Token indices:')\n",
        "tokenseq = encoder(wordseq,word2idx)\n",
        "print(tokenseq), print('')\n",
        "\n",
        "# decode\n",
        "print('Decoded text from indices:')\n",
        "decoder(tokenseq,idx2word)"
      ],
      "metadata": {
        "id": "nsJOMwjKaNpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "od2XevtsY3G9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}