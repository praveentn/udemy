{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyP9MjMb7rfJDfZqYtLb3pvH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n","|-|:-:|\n","|<h2>Part 1:</h2>|<h1>Tokenizations and embeddings<h1>|\n","|<h2>Section:</h2>|<h1>Words to tokens to numbers<h1>|\n","|<h2>Lecture:</h2>|<h1><b>CodeChallenge: Tokenization compression ratios<b></h1>|\n","\n","<br>\n","\n","<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n","<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">udemy.com/course/dullms_x/?couponCode=202508</a></h5>\n","<i>Using the code without the course may lead to confusion or errors.</i>"],"metadata":{"id":"fMIX8VSYc2Tm"}},{"cell_type":"code","source":[],"metadata":{"id":"0GmDlHtoc2Or"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C8JzcByJ_dVt"},"outputs":[],"source":["# for getting text data off the web\n","import requests\n","import re\n","from urllib.parse import urlparse\n","\n","# strings\n","import string\n","\n","!pip install tiktoken\n","import tiktoken"]},{"cell_type":"code","source":["# GPT-4's tokenizer\n","tokenizer = tiktoken.get_encoding('cl100k_base')"],"metadata":{"id":"f34QAbA-_gD-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Vll_zH5t_gHC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 1: The books"],"metadata":{"id":"nsfMaYxen8oU"}},{"cell_type":"code","source":["# all books have the same url format;\n","# they are unique by numerical code\n","baseurl = 'https://www.gutenberg.org/cache/epub/'\n","\n","bookurls = [\n","    # code       title\n","    ['84',    'Frankenstein'    ],\n","    ['64317', 'GreatGatsby'     ],\n","    ['11',    'AliceWonderland' ],\n","    ['1513',  'RomeoJuliet'     ],\n","    ['76',    'HuckFinn'        ],\n","    ['219',   'HeartDarkness'   ],\n","    ['2591',  'GrimmsTales'     ],\n","    ['2148',  'EdgarAllenPoe'   ],\n","    ['36',    'WarOfTheWorlds'  ],\n","    ['829',   'GulliversTravels']\n","]"],"metadata":{"id":"fX_ZgpveSYPL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('  Book title     |  Chars  |  Tokens | Compression')\n","print('-'*50)\n","\n","for code,title in bookurls:\n","\n","  # get the text\n","  fullurl = baseurl + code + '/pg' + code + '.txt'\n","  text = requests.get(fullurl).text\n","  num_chars = len(text)\n","\n","  # tokenize\n","  tokens = tokenizer.encode(text)\n","  num_tokens = len(tokens)\n","\n","  # compression ratio\n","  compress = 100*num_tokens/num_chars\n","\n","  print(f'{title:16} | {num_chars:>7,d} | {num_tokens:>7,d} |  {compress:>3.2f}%')"],"metadata":{"id":"AW2MzjfdRhB8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"5G8IwDojRg_E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 2: Repeat with websites"],"metadata":{"id":"0FZ6gF8zRg8H"}},{"cell_type":"code","source":["weburls = [\n","    'http://python.org/',\n","    'https://pytorch.org/',\n","    'https://en.wikipedia.org/wiki/List_of_English_words_containing_Q_not_followed_by_U',\n","    'https://sudoku.com/',\n","    'https://reddit.com/',\n","    'https://visiteurope.com/en/',\n","    'https://sincxpress.com/',\n","    'https://openai.com/',\n","    'https://theuselessweb.com/',\n","    'https://maps.google.com/',\n","    'https://pigeonsarentreal.co.uk/',\n","]"],"metadata":{"id":"KOTAgq4PXMVc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('    Website        |  Chars  |  Tokens | Compression')\n","print('-'*53)\n","\n","for url in weburls:\n","\n","  # get the text\n","  text = requests.get(url).text\n","  num_chars = len(text)\n","\n","  # tokenize\n","  tokens = tokenizer.encode(text)\n","  num_tokens = len(tokens)\n","\n","  # compression ratio\n","  compress = 100*num_tokens/num_chars\n","\n","  print(f'{urlparse(url).hostname[:-4]:18} | {num_chars:>7,d} | {num_tokens:>7,d} |  {compress:>3.2f}%')"],"metadata":{"id":"hC7ZulNxRg5K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"RczL4_fIWVBK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 3: Using the 'string' library"],"metadata":{"id":"xOShW7tBhftK"}},{"cell_type":"code","source":["print('  Attribute     |  Chars  |  Tokens | Compression')\n","print('-'*50)\n","\n","for k,v in string.__dict__.items():\n","  if isinstance(v,str) and (len(v)>0):\n","\n","    # get the text\n","    num_chars = len(v)\n","\n","    # tokenize\n","    tokens = tokenizer.encode(v)\n","    num_tokens = len(tokens)\n","\n","    # compression ratio\n","    compress = 100*num_tokens/num_chars\n","\n","    print(f'{k:15} | {num_chars:>7,d} | {num_tokens:>7,d} |  {compress:>5.2f}%')"],"metadata":{"id":"pozOkYnVfwSI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# e.g.,\n","string.__dict__['__doc__']\n","# string.ascii_lowercase"],"metadata":{"id":"i_3jPwujPEpV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"LmF_zWxheB1F"},"execution_count":null,"outputs":[]}]}