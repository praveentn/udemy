{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n",
        "|-|:-:|\n",
        "|<h2>Part 2:</h2>|<h1>Large language models<h1>|\n",
        "|<h2>Section:</h2>|<h1>Fine-tune pretrained models<h1>|\n",
        "|<h2>Lecture:</h2>|<h1><b>On generating text from pretrained models<b></h1>|\n",
        "\n",
        "<br>\n",
        "\n",
        "<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n",
        "<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">udemy.com/course/dullms_x/?couponCode=202508</a></h5>\n",
        "<i>Using the code without the course may lead to confusion or errors.</i>"
      ],
      "metadata": {
        "id": "2TO7fdkJIIgX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EjWotPXSzxp"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained GPT2 tokenizer and model\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-medium')\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2-medium')"
      ],
      "metadata": {
        "id": "s_W8oErYTGjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JWUHXHKXUMkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pad token"
      ],
      "metadata": {
        "id": "grEVTCtbUMdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GPT-2 does not set a pad token\n",
        "print('Current pad token: ',tokenizer.pad_token)\n",
        "print('Current eos token: ',tokenizer.eos_token)\n",
        "\n",
        "# common (though not necessarily ideal) to set pad_token = eos_token\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model.config.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "print('Current pad token: ',tokenizer.pad_token)"
      ],
      "metadata": {
        "id": "Hgxk1Ch-TMpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TNO1tfXdTMj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoding"
      ],
      "metadata": {
        "id": "IN9tzj3NTMhB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    'Every happy family is the same',\n",
        "    'every unhappy family is unhappy it its own way.',\n",
        "    'Why did the chicken cross the road?']\n",
        "\n",
        "# tokenize with padding and attention mask\n",
        "toks = tokenizer(\n",
        "    sentences,\n",
        "    return_tensors = 'pt',\n",
        "    padding = True )\n",
        "\n",
        "toks"
      ],
      "metadata": {
        "id": "IUji4H0yTKD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(sentences)):\n",
        "\n",
        "  inputs = toks['input_ids'][i]\n",
        "  mask = toks['attention_mask'][i]\n",
        "\n",
        "  print(f'\"{sentences[i]}\":')\n",
        "  print(inputs,'\\n',mask,'\\n')"
      ],
      "metadata": {
        "id": "lAokPuwCVLOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MTQMqSxzUg_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate some text"
      ],
      "metadata": {
        "id": "XgOrfdjPUg9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model.generate(\n",
        "    input_ids      = toks['input_ids'],\n",
        "    attention_mask = toks['attention_mask'],\n",
        "    pad_token_id   = tokenizer.pad_token_id,\n",
        "    max_length     = 66,\n",
        "    num_return_sequences = 1,\n",
        "    do_sample      = True,\n",
        "    top_k          = 50,\n",
        "    top_p          = .95\n",
        ")\n",
        "\n",
        "outputs"
      ],
      "metadata": {
        "id": "M86W5gkVUeEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.shape"
      ],
      "metadata": {
        "id": "E3tq2cJPLiq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# decode\n",
        "decoded_texts = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "\n",
        "for i,text in enumerate(decoded_texts):\n",
        "    print(f'*** Text {i+1}:\\n{text}\\n')"
      ],
      "metadata": {
        "id": "cdzXb3jOUReA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W_57LwbaVAXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# or simpler:\n",
        "model.generate(toks['input_ids'])"
      ],
      "metadata": {
        "id": "b0670cyMWb_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w-3Oj2KbWb9A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}