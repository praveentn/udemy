{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"1jmWytQcLQdHCqDzcEt7q1GICCdPBxZ3T","timestamp":1742377210164}],"machine_shape":"hm","gpuType":"L4","authorship_tag":"ABX9TyPD7UIjiHzE1r6ga3XEIQfB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n","|-|:-:|\n","|<h2>Part 2:</h2>|<h1>Large language models<h1>|\n","|<h2>Section:</h2>|<h1>Pretrain LLMs<h1>|\n","|<h2>Lecture:</h2>|<h1><b>CodeChallenge HELPER: Add a test set<b></h1>|\n","\n","<br>\n","\n","<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n","<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">udemy.com/course/dullms_x/?couponCode=202508</a></h5>\n","<i>Using the code without the course may lead to confusion or errors.</i>"],"metadata":{"id":"DbxTImu7B1KB"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"REAnIB2kIp_A"},"outputs":[],"source":["import numpy as np\n","import requests\n","import matplotlib.pyplot as plt\n","\n","# note the random_split\n","from torch.utils.data import Dataset, DataLoader, random_split\n","import torch\n","import torch.nn as nn\n","from torch.nn import functional as F"]},{"cell_type":"code","source":["# GPT-2's tokenizer\n","from transformers import GPT2Tokenizer\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"],"metadata":{"id":"4txp8aK9K_dx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"B3ap39h0Jjdy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"cHj5D0oSDMoF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Hyperparameters"],"metadata":{"id":"Gi-0zIzafVUo"}},{"cell_type":"code","source":["# data hyperparameters\n","seq_len = 8 # aka context length\n","stride = 2\n","\n","# model hyperparameters\n","embed_dim = 128\n","\n","# training hyperparameters\n","batch_size = 64"],"metadata":{"id":"u0j1AmufJjg8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"LAp4k3HzfXCp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 1: Create train and test sets"],"metadata":{"id":"gJWJc9eo6r7e"}},{"cell_type":"code","source":["# download and tokenize the text\n","text = requests.get('https://www.gutenberg.org/files/35/35-0.txt').text\n","tmTokens = torch.tensor( tokenizer.encode(text) )\n","\n","# count the number of tokens"],"metadata":{"id":"4ROffDzOJqh7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create a class for a dataset (note: batching is done by the DataLoader, not in the dataset)\n","class TokenDataset(Dataset):\n","  def __init__(self, tokens, seq_len=8, stride=4):\n","\n","    # initialize\n","    self.inputs  = []\n","    self.targets = []\n","\n","    # overlapping sequences of seq_len\n","    for i in range(0,len(tokens)-seq_len,stride):\n","\n","      # get c tokens and append to the lists\n","      self.inputs.append( tokens[i   : i+seq_len])\n","      self.targets.append(tokens[ : ])\n","\n","  def __len__(self):\n","    return len(self.inputs)\n","\n","  def __getitem__(self, idx):\n","    return self.inputs[idx], self.targets[idx]"],"metadata":{"id":"-d-Yg-XgJjYs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create an instance\n","token_dataset = TokenDataset(tmTokens,seq_len,stride)\n","\n","# split into train and test\n","train_ratio = .9\n","train_size =\n","test_size  =\n","\n","# create train/test subsets\n","train_dataset, test_dataset = random_split(\n","    token_dataset, [train_size, test_size])\n","\n","# create DataLoaders\n","train_dataloader = DataLoader(, , shuffle=True)\n","test_dataloader  = DataLoader(, , shuffle=False)\n","\n","print(f'Train set has {} sequences.')\n","print(f'Test set has  {} sequences.')"],"metadata":{"id":"OKCFDygz7XHM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"QNwmxlH40hGe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 2: Create the model"],"metadata":{"id":"GjK4KWn9jQXO"}},{"cell_type":"code","source":["class Model(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","\n","    # embedding matrix\n","    self.embedding = nn.Embedding(,)\n","\n","    # embedding to output (linear) layer\n","    self.gelu = nn.GELU()\n","    self.finalLinear = nn.Linear(,,bias=False)\n","\n","\n","\n","  def forward(self,tokx):\n","\n","    # forward pass\n","    x =  # push through embeddings; size will be [batch, token, embedding dimension]\n","    x =  # gelu\n","    x =  # final linear layer\n","\n","    # return log-softmax\n","    return # make sure the log-softmax is applied across the correct dimension\n","\n","  def generate(self,tokx,n_new_tokens=30):\n","    for _ in range(n_new_tokens):\n","      x = # push through the model\n","      x = # keep only the final token\n","      probs = # undo the log, keep the softmax\n","      tokx_next = torch.multinomial # get one probabalistic sample\n","      tokx = # concatenate the new token onto the sequence\n","    return tokx\n"],"metadata":{"id":"lpG1Af9RjQUY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create an instance and test\n","model = Model()\n","X,y = # some data from the dataloader\n","out = # push through the model\n","\n","print(X.shape)\n","print(y.shape)\n","print(out.shape)"],"metadata":{"id":"SQoC6PTqbcRS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ODWHQSD1binT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# confirm the probability distribution\n","\n","print() # does sum(exp) == exp(sum)?\n","print( # smallest value\n","print( # largest value"],"metadata":{"id":"VRNKfUvZAJko"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"E9FhirCXzr-K"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 3: Training"],"metadata":{"id":"Hc9NQl0Hzr7U"}},{"cell_type":"code","source":["# push the model to the GPU\n"],"metadata":{"id":"Ae0mZC83y7tu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create the loss and optimizer functions\n","loss_function =\n","optimizer ="],"metadata":{"id":"qpcC47LUy7w6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_epochs = 10\n","\n","# initialize losses\n","train_loss = []\n","test_loss = []\n","\n","for epoch in range(num_epochs):\n","\n","  # initialize\n","  epoch_loss = 0\n","\n","  # loop over batches in the data loader\n","  for X,y in train_dataloader:\n","\n","    # move data to GPU\n","\n","\n","    # clear previous gradients\n","    model.z\n","\n","    # forward pass\n","    log_probs =\n","\n","    # calculate the losses on the (reshaped) final target word\n","    log_probs_flat = .view(-1,\n","    y_flat = y.view(-1)\n","    loss = loss_function(log_probs_flat, y_flat)\n","\n","    # backprop\n","\n","\n","\n","    # sum the per-epoch losses\n","    epoch_loss +=\n","  #- loop over batches ends here\n","\n","\n","  # evaluate the model with the test set\n","  with torch.no_grad():\n","    testloss = 0 # reset the test loss\n","    for X,y in test_dataloader:\n","        # push it to the GPU\n","      out =                     # forward pass\n","      out_flat =  # reshape output\n","      thisloss =  # calculate loss\n","      testloss += # add to the ongoing loss\n","\n","\n","\n","  # scale the train loss by the number of tokens in this dataloader\n","  train_loss.append(epoch_loss /\n","  test_loss.append(testloss /\n","\n","  # update our progress :)\n","  print(f'"],"metadata":{"id":"WUYuqpThHZL5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# plot the losses\n","plt.plot(train_loss\n","plt.plot(\n","\n","plt.legend()\n","plt.gca().set(xlabel='Epoch',ylabel='Loss')\n","plt.show()"],"metadata":{"id":"5XdjwacoHZOi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# generate new text\n","startToks = torch.tensor(tokenizer.encode('I thought the Eloi would be smarter than')).unsqueeze(0)\n","\n","# text generation\n"],"metadata":{"id":"RCr8wYOsy7l0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"XoyTa-GUWh-c"},"execution_count":null,"outputs":[]}]}