{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyNaIR2T/b2bb16/TXOFOHQH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n","|-|:-:|\n","|<h2>Part 3:</h2>|<h1>Evaluating LLMs<h1>|\n","|<h2>Section:</h2>|<h1>Quantitative evaluations<h1>|\n","|<h2>Lecture:</h2>|<h1><b>Numerical issues in logits and softmax<b></h1>|\n","\n","<br>\n","\n","<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n","<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">udemy.com/course/dullms_x/?couponCode=202508</a></h5>\n","<i>Using the code without the course may lead to confusion or errors.</i>"],"metadata":{"id":"urGeUxued5Qf"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"w6kR6FqjfpeL"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn.functional as F\n","from transformers import AutoModelForCausalLM, GPT2Tokenizer\n","\n","# vector plots\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"]},{"cell_type":"code","source":[],"metadata":{"id":"3i386vZJ49_Z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Import GPT2-small and -large"],"metadata":{"id":"RpYWC1Uu499X"}},{"cell_type":"code","source":["# load pretrained GPT-2 model and tokenizer\n","gpt2_small = AutoModelForCausalLM.from_pretrained('gpt2')\n","gpt2_large = AutoModelForCausalLM.from_pretrained('gpt2-large')\n","\n","# and the tokenizer\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"],"metadata":{"id":"PsrX9u8K3AEG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"hyzluVtYefT_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Logits from both models for the same inputs"],"metadata":{"id":"d4yb0rPT_0Pv"}},{"cell_type":"code","source":["# get the outputs of the models\n","outputs_small = gpt2_small(tokenizer.encode('A plethora of platypuses.',return_tensors='pt'))\n","outputs_large = gpt2_large(tokenizer.encode('A plethora of platypuses.',return_tensors='pt'))"],"metadata":{"id":"vVFv6bJG7PhM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# grab the final token logit outputs\n","logits_small = outputs_small.logits[0,-1,:].detach()\n","logits_large = outputs_large.logits[0,-1,:].detach()\n","\n","_,axs = plt.subplots(1,3,figsize=(12,3.5))\n","\n","# gpt2 small\n","axs[0].plot(logits_small,'k.',alpha=.2)\n","axs[0].set(xlim=[-10,tokenizer.vocab_size+9],xlabel='Token index',ylabel='Output logits',title='GPT2 SMALL')\n","\n","# gpt2 large\n","axs[1].plot(logits_large,'k.',alpha=.2)\n","axs[1].set(xlim=[-10,tokenizer.vocab_size+9],xlabel='Token index',ylabel='Output logits',title='GPT2 LARGE')\n","\n","# against each other\n","axs[2].plot(logits_small,logits_large,'b.',alpha=.2)\n","axs[2].set(xlabel='GPT2 SMALL',ylabel='GPT2 LARGE',title='Comparison of both models')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"HuxTwOnR7Pem"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"sDhrONsZAGu0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Manual softmax via direct implementation of the math"],"metadata":{"id":"kHwIJhIhAGsJ"}},{"cell_type":"code","source":["# manual softmax\n","sm_manual_small = torch.exp(logits_small) / torch.sum(torch.exp(logits_small))\n","sm_manual_large = torch.exp(logits_large) / torch.sum(torch.exp(logits_large))\n","\n","_,axs = plt.subplots(1,3,figsize=(12,3.5))\n","\n","# gpt2 small\n","axs[0].plot(sm_manual_small,'k.',alpha=.2)\n","axs[0].set(xlim=[-10,tokenizer.vocab_size+9],xlabel='Token index',ylabel='Output logits',title='GPT2 SMALL')\n","\n","# gpt2 large\n","axs[1].plot(sm_manual_large,'k.',alpha=.2)\n","axs[1].set(xlim=[-10,tokenizer.vocab_size+9],xlabel='Token index',ylabel='Output logits',title='GPT2 LARGE')\n","\n","# against each other\n","axs[2].plot(sm_manual_small,sm_manual_large,'b.',alpha=.2)\n","axs[2].set(xlabel='GPT2 SMALL',ylabel='GPT2 LARGE',title='Comparison of both models')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"ENUE4s5B7Pbw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# uh oh...\n","sm_manual_small"],"metadata":{"id":"4JT2xG9-Z4n4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# wait but why?\n","logits_small_norm[10000]#.exp()\n","# logits_small.exp().sum()"],"metadata":{"id":"VQG_Y1LLeGUE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n = -123.0\n","print('numpy:',np.exp(n))\n","print('torch:',torch.exp(torch.tensor(n)))"],"metadata":{"id":"7PuK_hNle1_K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"wviNnnbOAKYU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Corrected softmax via normalization"],"metadata":{"id":"OgnmUOelAKVz"}},{"cell_type":"code","source":["# simple normalization (subtract max value)\n","logits_small_norm = logits_small - logits_small.max()\n","logits_large_norm = logits_large - logits_large.max()\n","\n","# visualize\n","_,axs = plt.subplots(1,3,figsize=(12,3.5))\n","\n","# gpt2 small\n","axs[0].plot(logits_small_norm,'k.',alpha=.2)\n","axs[0].set(xlim=[-10,tokenizer.vocab_size+9],xlabel='Token index',ylabel='Output logits',title='GPT2 SMALL')\n","\n","# gpt2 large\n","axs[1].plot(logits_large_norm,'k.',alpha=.2)\n","axs[1].set(xlim=[-10,tokenizer.vocab_size+9],xlabel='Token index',ylabel='Output logits',title='GPT2 LARGE')\n","\n","# against each other\n","axs[2].plot(logits_small_norm,logits_large_norm,'b.',alpha=.2)\n","axs[2].set(xlabel='GPT2 SMALL',ylabel='GPT2 LARGE',title='Comparison of both models')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"5f1s4XI47PY-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# now repeat the manual softmax\n","sm_manual_smallN = torch.exp(logits_small_norm) / torch.sum(torch.exp(logits_small_norm))\n","sm_manual_largeN = torch.exp(logits_large_norm) / torch.sum(torch.exp(logits_large_norm))\n","\n","_,axs = plt.subplots(1,3,figsize=(12,3.5))\n","\n","# gpt2 small\n","axs[0].plot(sm_manual_smallN,'k.',alpha=.2)\n","axs[0].set(xlim=[-10,tokenizer.vocab_size+9],xlabel='Token index',ylabel='Output logits',title='GPT2 SMALL')\n","\n","# gpt2 large\n","axs[1].plot(sm_manual_largeN,'k.',alpha=.2)\n","axs[1].set(xlim=[-10,tokenizer.vocab_size+9],xlabel='Token index',ylabel='Output logits',title='GPT2 LARGE')\n","\n","# against each other\n","axs[2].plot(sm_manual_smallN,sm_manual_largeN,'b.',alpha=.2)\n","axs[2].set(xlabel='GPT2 SMALL',ylabel='GPT2 LARGE',title='Comparison of both models')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"kJIyRzvPAQVP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"el598cFqAf-7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Pytorch softmax function"],"metadata":{"id":"hzlWMrCMAf8Q"}},{"cell_type":"code","source":["# pytorch softmax\n","sm_torch_small = F.softmax(logits_small,dim=-1)\n","sm_torch_large = F.softmax(logits_large,dim=-1)\n","\n","_,axs = plt.subplots(1,3,figsize=(12,3.5))\n","\n","# gpt2 small\n","axs[0].plot(sm_torch_small,'k.',alpha=.2)\n","axs[0].set(xlim=[-10,tokenizer.vocab_size+9],xlabel='Token index',ylabel='Output logits',title='GPT2 SMALL')\n","\n","# gpt2 large\n","axs[1].plot(sm_torch_large,'k.',alpha=.2)\n","axs[1].set(xlim=[-10,tokenizer.vocab_size+9],xlabel='Token index',ylabel='Output logits',title='GPT2 LARGE')\n","\n","# against each other\n","axs[2].plot(sm_torch_small,sm_torch_large,'b.',alpha=.2)\n","axs[2].set(xlabel='GPT2 SMALL',ylabel='GPT2 LARGE',title='Comparison of both models')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"6puCsem-7PWU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["F.softmax??"],"metadata":{"id":"zmD1zpU26VJw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xBbEE2F6aOxQ"},"execution_count":null,"outputs":[]}]}